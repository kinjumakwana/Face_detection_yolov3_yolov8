{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa805b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48127691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# # Load a model\n",
    "# model = YOLO('yolov8n.pt')\n",
    "\n",
    "# source = 'https://ultralytics.com/images/bus.jpg'\n",
    "# results = model.predict(source, save=True, imgsz=320, conf=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16edf7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\BAPS\\\\Documents'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb28bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.10.9 torch-2.0.1+cpu CPU (Intel Core(TM) i5-8365U 1.60GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=D:/Face Detection_yolov8/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\BAPS\\runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Users\\BAPS\\runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Face Detection_yolov8\\train\\labels... 190 images, 0 backgrounds, 0 corrupt: 100%|██████████| 190/190\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Face Detection_yolov8\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Face Detection_yolov8\\valid\\labels... 55 images, 0 backgrounds, 0 corrupt: 100%|██████████| 55/55 [00:\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Face Detection_yolov8\\valid\\labels.cache\n",
      "Plotting labels to C:\\Users\\BAPS\\runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50         0G      1.742      3.238       1.89         40        640: 100%|██████████| 12/12 [02:34<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         55         60          1      0.346      0.793       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50         0G      1.441      1.942       1.36         36        640: 100%|██████████| 12/12 [02:35<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:19<0\n",
      "                   all         55         60      0.571      0.886      0.856      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50         0G      1.418      1.643      1.299         31        640: 100%|██████████| 12/12 [02:24<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.761      0.733      0.804      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50         0G      1.437      1.559      1.358         36        640: 100%|██████████| 12/12 [02:21<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60        0.9      0.748       0.84      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50         0G      1.511      1.573      1.357         28        640: 100%|██████████| 12/12 [02:22<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         55         60      0.743      0.783      0.776       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50         0G      1.504      1.536      1.357         29        640: 100%|██████████| 12/12 [02:23<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.673      0.822       0.75       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50         0G      1.435      1.433      1.349         28        640: 100%|██████████| 12/12 [02:25<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         55         60      0.816      0.783      0.852      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50         0G       1.42      1.394      1.352         29        640: 100%|██████████| 12/12 [02:22<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.689      0.833      0.814      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50         0G       1.45      1.323      1.351         31        640: 100%|██████████| 12/12 [02:20<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.892      0.829      0.899      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50         0G      1.508      1.335      1.391         29        640: 100%|██████████| 12/12 [02:23<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.633       0.75       0.68       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50         0G      1.462      1.278       1.32         34        640: 100%|██████████| 12/12 [02:20<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.921      0.767       0.87      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50         0G        1.5      1.211      1.343         23        640: 100%|██████████| 12/12 [02:20<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.793      0.893      0.893       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50         0G      1.475      1.205      1.372         45        640: 100%|██████████| 12/12 [02:21<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.895      0.833      0.882      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50         0G      1.435      1.149      1.317         41        640: 100%|██████████| 12/12 [02:21<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.889      0.817      0.884      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50         0G      1.423      1.132      1.304         28        640: 100%|██████████| 12/12 [02:22<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.861      0.883      0.906      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50         0G      1.426      1.095      1.318         27        640: 100%|██████████| 12/12 [02:22<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0\n",
      "                   all         55         60      0.965      0.911      0.957       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50         0G      1.444      1.083      1.344         20        640: 100%|██████████| 12/12 [02:26<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.968      0.917      0.935      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50         0G       1.37      1.047      1.276         25        640: 100%|██████████| 12/12 [02:20<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.942      0.867      0.912      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50         0G      1.358     0.9663      1.251         22        640: 100%|██████████| 12/12 [02:28<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.993        0.8      0.864      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50         0G      1.315     0.9493      1.256         25        640: 100%|██████████| 12/12 [02:29<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.979      0.967      0.963      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50         0G      1.378     0.9308      1.252         26        640: 100%|██████████| 12/12 [02:24<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.949      0.927      0.942      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50         0G      1.373     0.9438      1.277         29        640: 100%|██████████| 12/12 [02:18<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.971       0.95      0.971      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50         0G        1.3     0.9192      1.244         30        640: 100%|██████████| 12/12 [02:32<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.919       0.95      0.935      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50         0G      1.288     0.8539      1.225         23        640: 100%|██████████| 12/12 [02:32<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.979        0.9       0.96      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50         0G      1.343     0.8512      1.233         28        640: 100%|██████████| 12/12 [02:29<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.904      0.942      0.953       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50         0G      1.265      0.791      1.218         24        640: 100%|██████████| 12/12 [02:31<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.882       0.87      0.923      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G      1.273     0.8263      1.219         30        640: 100%|██████████| 12/12 [02:18<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.966      0.943      0.957      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50         0G      1.309     0.7937      1.214         28        640: 100%|██████████| 12/12 [02:17<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.981       0.95      0.959      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50         0G      1.257     0.7617      1.221         20        640: 100%|██████████| 12/12 [02:26<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.993       0.95       0.96      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50         0G      1.265     0.7861      1.199         22        640: 100%|██████████| 12/12 [02:26<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.999      0.917      0.961       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50         0G      1.227     0.7429      1.204         29        640: 100%|██████████| 12/12 [02:28<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60          1      0.945      0.963      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50         0G      1.243     0.7351      1.209         34        640: 100%|██████████| 12/12 [02:33<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.965      0.932      0.944      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50         0G      1.166     0.6884      1.185         23        640: 100%|██████████| 12/12 [02:28<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60          1      0.933      0.973      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50         0G      1.179     0.6987      1.161         38        640: 100%|██████████| 12/12 [02:20<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.982       0.95       0.98      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50         0G      1.172     0.7107      1.175         45        640: 100%|██████████| 12/12 [02:31<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.983      0.965      0.978      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50         0G      1.187     0.7013      1.145         35        640: 100%|██████████| 12/12 [02:31<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.983      0.965       0.97        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50         0G      1.128     0.7038      1.145         30        640: 100%|██████████| 12/12 [02:30<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:17<0\n",
      "                   all         55         60      0.967      0.965      0.964      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50         0G      1.104     0.6543      1.143         44        640: 100%|██████████| 12/12 [02:27<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0\n",
      "                   all         55         60      0.981       0.95      0.963      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50         0G      1.173     0.7038      1.181         29        640: 100%|██████████| 12/12 [02:16<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0\n",
      "                   all         55         60      0.981       0.95      0.964      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50         0G       1.12      0.661      1.148         28        640: 100%|██████████| 12/12 [02:21<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60       0.98       0.95      0.964      0.589\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50         0G      1.069     0.6381      1.172         26        640: 100%|██████████| 12/12 [02:22<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0\n",
      "                   all         55         60      0.982       0.95      0.967      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50         0G      1.087     0.6341      1.179         19        640: 100%|██████████| 12/12 [02:18<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.967      0.965      0.971        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50         0G      1.025     0.5983       1.08         15        640: 100%|██████████| 12/12 [02:21<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.965      0.967      0.979      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50         0G      1.045     0.5839       1.14         23        640: 100%|██████████| 12/12 [02:20<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0\n",
      "                   all         55         60      0.964      0.967       0.98      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50         0G      1.029     0.5733      1.124         16        640: 100%|██████████| 12/12 [02:21<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.981      0.967      0.979       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50         0G      1.016     0.5625      1.141         16        640: 100%|██████████| 12/12 [02:30<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.963      0.967      0.972        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50         0G     0.9815     0.5511      1.113         16        640: 100%|██████████| 12/12 [02:36<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.983      0.962      0.981      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50         0G     0.9503     0.5325       1.09         14        640: 100%|██████████| 12/12 [02:17<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0\n",
      "                   all         55         60      0.963       0.95      0.977      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50         0G     0.9643     0.5537      1.123         15        640: 100%|██████████| 12/12 [02:17<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:15<0\n",
      "                   all         55         60      0.979       0.95      0.975      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50         0G     0.9544     0.5601      1.096         15        640: 100%|██████████| 12/12 [02:33<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         55         60      0.983      0.964      0.978      0.603\n",
      "\n",
      "50 epochs completed in 2.259 hours.\n",
      "Optimizer stripped from C:\\Users\\BAPS\\runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.181  Python-3.10.9 torch-2.0.1+cpu CPU (Intel Core(TM) i5-8365U 1.60GHz)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<0\n",
      "                   all         55         60      0.965      0.967      0.979      0.604\n",
      "Speed: 3.3ms preprocess, 239.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# custome Model \n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=r'D:/Face Detection_yolov8/data.yaml', epochs=50, imgsz=640, lr0=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff5e5ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Face Detection_yolov8\\image1.jpg: 640x640 1 Face, 343.6ms\n",
      "Speed: 0.0ms preprocess, 343.6ms inference, 15.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')# load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt')  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model(r'D:\\Face Detection_yolov8\\image1.jpg', save=True, conf=0.5)  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8fed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 240.2ms\n",
      "video 1/1 (2/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 154.1ms\n",
      "video 1/1 (3/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 131.5ms\n",
      "video 1/1 (4/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 127.3ms\n",
      "video 1/1 (5/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 146.2ms\n",
      "video 1/1 (6/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 134.4ms\n",
      "video 1/1 (7/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 147.7ms\n",
      "video 1/1 (8/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 127.7ms\n",
      "video 1/1 (9/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 125.4ms\n",
      "video 1/1 (10/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 146.4ms\n",
      "video 1/1 (11/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.9ms\n",
      "video 1/1 (12/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 141.5ms\n",
      "video 1/1 (13/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 116.2ms\n",
      "video 1/1 (14/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 127.7ms\n",
      "video 1/1 (15/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.3ms\n",
      "video 1/1 (16/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 123.7ms\n",
      "video 1/1 (17/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 126.0ms\n",
      "video 1/1 (18/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 143.3ms\n",
      "video 1/1 (19/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 129.7ms\n",
      "video 1/1 (20/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 133.8ms\n",
      "video 1/1 (21/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.2ms\n",
      "video 1/1 (22/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 122.0ms\n",
      "video 1/1 (23/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.8ms\n",
      "video 1/1 (24/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 131.7ms\n",
      "video 1/1 (25/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 124.6ms\n",
      "video 1/1 (26/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 101.6ms\n",
      "video 1/1 (27/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 129.8ms\n",
      "video 1/1 (28/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.1ms\n",
      "video 1/1 (29/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.6ms\n",
      "video 1/1 (30/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.9ms\n",
      "video 1/1 (31/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.5ms\n",
      "video 1/1 (32/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.7ms\n",
      "video 1/1 (33/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 100.5ms\n",
      "video 1/1 (34/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 124.3ms\n",
      "video 1/1 (35/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 152.7ms\n",
      "video 1/1 (36/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 154.0ms\n",
      "video 1/1 (37/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 132.4ms\n",
      "video 1/1 (38/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 142.8ms\n",
      "video 1/1 (39/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 131.0ms\n",
      "video 1/1 (40/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 134.4ms\n",
      "video 1/1 (41/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 150.5ms\n",
      "video 1/1 (42/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 135.4ms\n",
      "video 1/1 (43/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 132.8ms\n",
      "video 1/1 (44/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 137.6ms\n",
      "video 1/1 (45/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 113.5ms\n",
      "video 1/1 (46/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 123.9ms\n",
      "video 1/1 (47/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 120.7ms\n",
      "video 1/1 (48/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 131.5ms\n",
      "video 1/1 (49/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 123.9ms\n",
      "video 1/1 (50/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.5ms\n",
      "video 1/1 (51/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 117.8ms\n",
      "video 1/1 (52/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 109.1ms\n",
      "video 1/1 (53/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 135.5ms\n",
      "video 1/1 (54/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.0ms\n",
      "video 1/1 (55/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 146.2ms\n",
      "video 1/1 (56/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 114.0ms\n",
      "video 1/1 (57/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 138.9ms\n",
      "video 1/1 (58/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 143.5ms\n",
      "video 1/1 (59/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 137.2ms\n",
      "video 1/1 (60/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 145.5ms\n",
      "video 1/1 (61/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.8ms\n",
      "video 1/1 (62/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 154.7ms\n",
      "video 1/1 (63/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 117.9ms\n",
      "video 1/1 (64/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 156.9ms\n",
      "video 1/1 (65/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 136.1ms\n",
      "video 1/1 (66/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 108.2ms\n",
      "video 1/1 (67/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 141.7ms\n",
      "video 1/1 (68/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 141.7ms\n",
      "video 1/1 (69/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 156.5ms\n",
      "video 1/1 (70/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 156.9ms\n",
      "video 1/1 (71/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 138.0ms\n",
      "video 1/1 (72/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 146.1ms\n",
      "video 1/1 (73/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 106.8ms\n",
      "video 1/1 (74/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 130.5ms\n",
      "video 1/1 (75/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 154.0ms\n",
      "video 1/1 (76/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 102.7ms\n",
      "video 1/1 (77/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 130.9ms\n",
      "video 1/1 (78/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 161.5ms\n",
      "video 1/1 (79/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 148.3ms\n",
      "video 1/1 (80/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 107.6ms\n",
      "video 1/1 (81/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.0ms\n",
      "video 1/1 (82/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.4ms\n",
      "video 1/1 (83/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 124.1ms\n",
      "video 1/1 (84/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 132.6ms\n",
      "video 1/1 (85/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.1ms\n",
      "video 1/1 (86/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 135.2ms\n",
      "video 1/1 (87/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 203.4ms\n",
      "video 1/1 (88/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 199.1ms\n",
      "video 1/1 (89/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 108.3ms\n",
      "video 1/1 (90/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 116.5ms\n",
      "video 1/1 (91/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 124.2ms\n",
      "video 1/1 (92/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.3ms\n",
      "video 1/1 (93/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.6ms\n",
      "video 1/1 (94/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.9ms\n",
      "video 1/1 (95/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.8ms\n",
      "video 1/1 (96/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 151.1ms\n",
      "video 1/1 (97/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 125.8ms\n",
      "video 1/1 (98/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 163.8ms\n",
      "video 1/1 (99/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 179.2ms\n",
      "video 1/1 (100/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 159.6ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (101/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 167.1ms\n",
      "video 1/1 (102/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.0ms\n",
      "video 1/1 (103/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 141.7ms\n",
      "video 1/1 (104/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 142.5ms\n",
      "video 1/1 (105/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 147.8ms\n",
      "video 1/1 (106/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 146.1ms\n",
      "video 1/1 (107/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.3ms\n",
      "video 1/1 (108/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 155.5ms\n",
      "video 1/1 (109/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 151.4ms\n",
      "video 1/1 (110/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 161.4ms\n",
      "video 1/1 (111/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 147.1ms\n",
      "video 1/1 (112/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.7ms\n",
      "video 1/1 (113/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.0ms\n",
      "video 1/1 (114/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 154.7ms\n",
      "video 1/1 (115/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 155.0ms\n",
      "video 1/1 (116/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 147.7ms\n",
      "video 1/1 (117/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 110.6ms\n",
      "video 1/1 (118/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 141.2ms\n",
      "video 1/1 (119/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.0ms\n",
      "video 1/1 (120/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 143.9ms\n",
      "video 1/1 (121/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 155.9ms\n",
      "video 1/1 (122/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.0ms\n",
      "video 1/1 (123/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.2ms\n",
      "video 1/1 (124/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 165.0ms\n",
      "video 1/1 (125/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.2ms\n",
      "video 1/1 (126/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 131.0ms\n",
      "video 1/1 (127/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 158.7ms\n",
      "video 1/1 (128/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 153.7ms\n",
      "video 1/1 (129/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 114.4ms\n",
      "video 1/1 (130/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 133.7ms\n",
      "video 1/1 (131/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.8ms\n",
      "video 1/1 (132/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 3 Faces, 140.3ms\n",
      "video 1/1 (133/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 120.6ms\n",
      "video 1/1 (134/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 122.8ms\n",
      "video 1/1 (135/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 149.0ms\n",
      "video 1/1 (136/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 145.5ms\n",
      "video 1/1 (137/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.2ms\n",
      "video 1/1 (138/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 156.7ms\n",
      "video 1/1 (139/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 120.3ms\n",
      "video 1/1 (140/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 151.8ms\n",
      "video 1/1 (141/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 148.5ms\n",
      "video 1/1 (142/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 163.0ms\n",
      "video 1/1 (143/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 152.7ms\n",
      "video 1/1 (144/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 137.5ms\n",
      "video 1/1 (145/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 156.4ms\n",
      "video 1/1 (146/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 144.2ms\n",
      "video 1/1 (147/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 132.2ms\n",
      "video 1/1 (148/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 151.0ms\n",
      "video 1/1 (149/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 133.5ms\n",
      "video 1/1 (150/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 157.6ms\n",
      "video 1/1 (151/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 131.6ms\n",
      "video 1/1 (152/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 178.6ms\n",
      "video 1/1 (153/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 208.2ms\n",
      "video 1/1 (154/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.8ms\n",
      "video 1/1 (155/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 159.5ms\n",
      "video 1/1 (156/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 156.9ms\n",
      "video 1/1 (157/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 133.8ms\n",
      "video 1/1 (158/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 144.9ms\n",
      "video 1/1 (159/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.5ms\n",
      "video 1/1 (160/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 142.4ms\n",
      "video 1/1 (161/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 159.5ms\n",
      "video 1/1 (162/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 135.3ms\n",
      "video 1/1 (163/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 137.4ms\n",
      "video 1/1 (164/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 135.4ms\n",
      "video 1/1 (165/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 130.7ms\n",
      "video 1/1 (166/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 116.8ms\n",
      "video 1/1 (167/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 121.6ms\n",
      "video 1/1 (168/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 121.2ms\n",
      "video 1/1 (169/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 125.4ms\n",
      "video 1/1 (170/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 208.0ms\n",
      "video 1/1 (171/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 153.2ms\n",
      "video 1/1 (172/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 126.2ms\n",
      "video 1/1 (173/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 125.7ms\n",
      "video 1/1 (174/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 124.7ms\n",
      "video 1/1 (175/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 122.5ms\n",
      "video 1/1 (176/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 142.0ms\n",
      "video 1/1 (177/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 121.6ms\n",
      "video 1/1 (178/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 124.2ms\n",
      "video 1/1 (179/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 134.3ms\n",
      "video 1/1 (180/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 319.4ms\n",
      "video 1/1 (181/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 169.0ms\n",
      "video 1/1 (182/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 125.1ms\n",
      "video 1/1 (183/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 146.8ms\n",
      "video 1/1 (184/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.0ms\n",
      "video 1/1 (185/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.9ms\n",
      "video 1/1 (186/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.2ms\n",
      "video 1/1 (187/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.8ms\n",
      "video 1/1 (188/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 134.7ms\n",
      "video 1/1 (189/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.1ms\n",
      "video 1/1 (190/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 125.4ms\n",
      "video 1/1 (191/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.6ms\n",
      "video 1/1 (192/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 146.9ms\n",
      "video 1/1 (193/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.5ms\n",
      "video 1/1 (194/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 116.6ms\n",
      "video 1/1 (195/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 117.7ms\n",
      "video 1/1 (196/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 150.1ms\n",
      "video 1/1 (197/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.8ms\n",
      "video 1/1 (198/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 127.0ms\n",
      "video 1/1 (199/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 132.0ms\n",
      "video 1/1 (200/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 130.6ms\n",
      "video 1/1 (201/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 134.9ms\n",
      "video 1/1 (202/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 131.2ms\n",
      "video 1/1 (203/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 125.7ms\n",
      "video 1/1 (204/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 135.7ms\n",
      "video 1/1 (205/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 167.0ms\n",
      "video 1/1 (206/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 153.4ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (207/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.2ms\n",
      "video 1/1 (208/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 125.3ms\n",
      "video 1/1 (209/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 134.3ms\n",
      "video 1/1 (210/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 137.3ms\n",
      "video 1/1 (211/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 112.1ms\n",
      "video 1/1 (212/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 134.8ms\n",
      "video 1/1 (213/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.4ms\n",
      "video 1/1 (214/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.1ms\n",
      "video 1/1 (215/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 130.4ms\n",
      "video 1/1 (216/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 133.5ms\n",
      "video 1/1 (217/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 118.7ms\n",
      "video 1/1 (218/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.5ms\n",
      "video 1/1 (219/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 136.8ms\n",
      "video 1/1 (220/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 151.4ms\n",
      "video 1/1 (221/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 144.0ms\n",
      "video 1/1 (222/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 159.2ms\n",
      "video 1/1 (223/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 144.9ms\n",
      "video 1/1 (224/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 138.3ms\n",
      "video 1/1 (225/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 151.5ms\n",
      "video 1/1 (226/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 160.2ms\n",
      "video 1/1 (227/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 158.5ms\n",
      "video 1/1 (228/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 169.7ms\n",
      "video 1/1 (229/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 169.6ms\n",
      "video 1/1 (230/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 155.7ms\n",
      "video 1/1 (231/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 155.3ms\n",
      "video 1/1 (232/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 167.8ms\n",
      "video 1/1 (233/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 140.4ms\n",
      "video 1/1 (234/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 155.3ms\n",
      "video 1/1 (235/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 148.2ms\n",
      "video 1/1 (236/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 124.6ms\n",
      "video 1/1 (237/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 128.5ms\n",
      "video 1/1 (238/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 139.0ms\n",
      "video 1/1 (239/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 144.4ms\n",
      "video 1/1 (240/240) D:\\Face Detection_yolov8\\v1.mp4: 384x640 4 Faces, 141.0ms\n",
      "Speed: 4.7ms preprocess, 140.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')  # load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt')  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model(r'D:\\Face Detection_yolov8\\v1.mp4', save=True, conf=0.5)  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c507e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Faces, 836.2ms\n",
      "Speed: 22.4ms preprocess, 836.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 177.4ms\n",
      "Speed: 6.2ms preprocess, 177.4ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 237.8ms\n",
      "Speed: 0.0ms preprocess, 237.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 183.2ms\n",
      "Speed: 5.3ms preprocess, 183.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 177.8ms\n",
      "Speed: 0.0ms preprocess, 177.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 168.0ms\n",
      "Speed: 6.7ms preprocess, 168.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 166.7ms\n",
      "Speed: 3.0ms preprocess, 166.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 231.4ms\n",
      "Speed: 1.3ms preprocess, 231.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 157.6ms\n",
      "Speed: 7.0ms preprocess, 157.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 148.4ms\n",
      "Speed: 3.0ms preprocess, 148.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.6ms\n",
      "Speed: 6.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 128.0ms\n",
      "Speed: 5.0ms preprocess, 128.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 129.7ms\n",
      "Speed: 3.1ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 130.3ms\n",
      "Speed: 4.0ms preprocess, 130.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 139.7ms\n",
      "Speed: 1.9ms preprocess, 139.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 126.0ms\n",
      "Speed: 4.1ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 129.6ms\n",
      "Speed: 5.1ms preprocess, 129.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 137.0ms\n",
      "Speed: 0.7ms preprocess, 137.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 122.7ms\n",
      "Speed: 3.0ms preprocess, 122.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 130.6ms\n",
      "Speed: 3.0ms preprocess, 130.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 144.3ms\n",
      "Speed: 1.5ms preprocess, 144.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 142.2ms\n",
      "Speed: 3.3ms preprocess, 142.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 150.0ms\n",
      "Speed: 0.0ms preprocess, 150.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 144.1ms\n",
      "Speed: 0.0ms preprocess, 144.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 125.8ms\n",
      "Speed: 6.5ms preprocess, 125.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 146.4ms\n",
      "Speed: 3.1ms preprocess, 146.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 144.4ms\n",
      "Speed: 4.3ms preprocess, 144.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 136.7ms\n",
      "Speed: 8.0ms preprocess, 136.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 126.9ms\n",
      "Speed: 4.0ms preprocess, 126.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 117.9ms\n",
      "Speed: 1.7ms preprocess, 117.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 147.2ms\n",
      "Speed: 0.0ms preprocess, 147.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.4ms\n",
      "Speed: 3.3ms preprocess, 134.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.8ms\n",
      "Speed: 6.0ms preprocess, 140.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 117.3ms\n",
      "Speed: 0.0ms preprocess, 117.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 141.6ms\n",
      "Speed: 0.0ms preprocess, 141.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 136.2ms\n",
      "Speed: 4.2ms preprocess, 136.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 114.9ms\n",
      "Speed: 4.6ms preprocess, 114.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 109.3ms\n",
      "Speed: 3.7ms preprocess, 109.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.6ms\n",
      "Speed: 3.0ms preprocess, 134.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 138.6ms\n",
      "Speed: 2.4ms preprocess, 138.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 137.9ms\n",
      "Speed: 4.4ms preprocess, 137.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 125.4ms\n",
      "Speed: 2.6ms preprocess, 125.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 138.1ms\n",
      "Speed: 4.7ms preprocess, 138.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 116.0ms\n",
      "Speed: 4.2ms preprocess, 116.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Faces, 139.2ms\n",
      "Speed: 1.7ms preprocess, 139.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.2ms\n",
      "Speed: 3.4ms preprocess, 135.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 117.2ms\n",
      "Speed: 3.0ms preprocess, 117.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 122.3ms\n",
      "Speed: 0.0ms preprocess, 122.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 130.1ms\n",
      "Speed: 1.6ms preprocess, 130.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 128.6ms\n",
      "Speed: 4.0ms preprocess, 128.6ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 143.7ms\n",
      "Speed: 4.0ms preprocess, 143.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 158.6ms\n",
      "Speed: 2.7ms preprocess, 158.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 131.5ms\n",
      "Speed: 0.0ms preprocess, 131.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.4ms\n",
      "Speed: 2.5ms preprocess, 135.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 116.8ms\n",
      "Speed: 3.0ms preprocess, 116.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.1ms\n",
      "Speed: 4.0ms preprocess, 140.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.4ms\n",
      "Speed: 3.0ms preprocess, 134.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 110.3ms\n",
      "Speed: 4.0ms preprocess, 110.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 108.3ms\n",
      "Speed: 2.8ms preprocess, 108.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 136.4ms\n",
      "Speed: 2.3ms preprocess, 136.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 125.5ms\n",
      "Speed: 3.0ms preprocess, 125.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 141.1ms\n",
      "Speed: 3.0ms preprocess, 141.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 144.5ms\n",
      "Speed: 3.0ms preprocess, 144.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 134.4ms\n",
      "Speed: 3.5ms preprocess, 134.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 128.6ms\n",
      "Speed: 4.1ms preprocess, 128.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 139.1ms\n",
      "Speed: 2.0ms preprocess, 139.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 110.1ms\n",
      "Speed: 4.4ms preprocess, 110.1ms inference, 13.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 147.3ms\n",
      "Speed: 0.0ms preprocess, 147.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 132.5ms\n",
      "Speed: 0.0ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.8ms\n",
      "Speed: 2.0ms preprocess, 140.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 130.8ms\n",
      "Speed: 5.0ms preprocess, 130.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.5ms\n",
      "Speed: 0.0ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 130.9ms\n",
      "Speed: 2.0ms preprocess, 130.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 136.2ms\n",
      "Speed: 0.0ms preprocess, 136.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 143.0ms\n",
      "Speed: 0.0ms preprocess, 143.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 134.7ms\n",
      "Speed: 2.0ms preprocess, 134.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 120.5ms\n",
      "Speed: 4.4ms preprocess, 120.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 135.5ms\n",
      "Speed: 0.0ms preprocess, 135.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 111.6ms\n",
      "Speed: 4.5ms preprocess, 111.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 148.9ms\n",
      "Speed: 0.0ms preprocess, 148.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 119.4ms\n",
      "Speed: 2.0ms preprocess, 119.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 138.5ms\n",
      "Speed: 2.8ms preprocess, 138.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 136.7ms\n",
      "Speed: 0.0ms preprocess, 136.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 138.3ms\n",
      "Speed: 3.0ms preprocess, 138.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 126.8ms\n",
      "Speed: 0.0ms preprocess, 126.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 134.0ms\n",
      "Speed: 2.0ms preprocess, 134.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 116.0ms\n",
      "Speed: 0.0ms preprocess, 116.0ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 129.8ms\n",
      "Speed: 2.3ms preprocess, 129.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 Faces, 149.3ms\n",
      "Speed: 0.0ms preprocess, 149.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 121.3ms\n",
      "Speed: 2.9ms preprocess, 121.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 130.4ms\n",
      "Speed: 2.0ms preprocess, 130.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 133.6ms\n",
      "Speed: 0.0ms preprocess, 133.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 136.2ms\n",
      "Speed: 2.5ms preprocess, 136.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 126.3ms\n",
      "Speed: 3.2ms preprocess, 126.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 133.1ms\n",
      "Speed: 0.0ms preprocess, 133.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 137.7ms\n",
      "Speed: 2.5ms preprocess, 137.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 126.1ms\n",
      "Speed: 1.0ms preprocess, 126.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 131.6ms\n",
      "Speed: 1.7ms preprocess, 131.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 138.2ms\n",
      "Speed: 0.0ms preprocess, 138.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 129.2ms\n",
      "Speed: 4.5ms preprocess, 129.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 142.1ms\n",
      "Speed: 3.1ms preprocess, 142.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 139.9ms\n",
      "Speed: 1.8ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 137.6ms\n",
      "Speed: 0.0ms preprocess, 137.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.1ms\n",
      "Speed: 0.0ms preprocess, 140.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 143.6ms\n",
      "Speed: 3.3ms preprocess, 143.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 144.5ms\n",
      "Speed: 2.0ms preprocess, 144.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 150.3ms\n",
      "Speed: 3.0ms preprocess, 150.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 3 Faces, 132.7ms\n",
      "Speed: 2.0ms preprocess, 132.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 114.4ms\n",
      "Speed: 4.0ms preprocess, 114.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 147.1ms\n",
      "Speed: 0.0ms preprocess, 147.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.2ms\n",
      "Speed: 2.0ms preprocess, 134.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 129.5ms\n",
      "Speed: 0.0ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 124.7ms\n",
      "Speed: 2.1ms preprocess, 124.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 141.9ms\n",
      "Speed: 2.0ms preprocess, 141.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 143.5ms\n",
      "Speed: 4.0ms preprocess, 143.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 145.4ms\n",
      "Speed: 0.0ms preprocess, 145.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 130.3ms\n",
      "Speed: 5.5ms preprocess, 130.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 129.0ms\n",
      "Speed: 0.0ms preprocess, 129.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 148.2ms\n",
      "Speed: 2.1ms preprocess, 148.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 137.4ms\n",
      "Speed: 3.3ms preprocess, 137.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 117.4ms\n",
      "Speed: 6.0ms preprocess, 117.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 152.6ms\n",
      "Speed: 1.1ms preprocess, 152.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 128.1ms\n",
      "Speed: 3.0ms preprocess, 128.1ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.6ms\n",
      "Speed: 3.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 141.8ms\n",
      "Speed: 3.1ms preprocess, 141.8ms inference, 12.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 165.9ms\n",
      "Speed: 3.0ms preprocess, 165.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 147.9ms\n",
      "Speed: 4.0ms preprocess, 147.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 148.2ms\n",
      "Speed: 2.4ms preprocess, 148.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 151.8ms\n",
      "Speed: 2.0ms preprocess, 151.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.9ms\n",
      "Speed: 2.0ms preprocess, 134.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 146.3ms\n",
      "Speed: 2.7ms preprocess, 146.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Faces, 153.4ms\n",
      "Speed: 3.1ms preprocess, 153.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 137.2ms\n",
      "Speed: 4.4ms preprocess, 137.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 152.0ms\n",
      "Speed: 4.0ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 151.7ms\n",
      "Speed: 2.4ms preprocess, 151.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 132.0ms\n",
      "Speed: 3.1ms preprocess, 132.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 133.5ms\n",
      "Speed: 0.0ms preprocess, 133.5ms inference, 15.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 133.0ms\n",
      "Speed: 1.7ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.0ms\n",
      "Speed: 0.0ms preprocess, 134.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 147.3ms\n",
      "Speed: 2.6ms preprocess, 147.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.1ms\n",
      "Speed: 3.0ms preprocess, 140.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 152.3ms\n",
      "Speed: 0.0ms preprocess, 152.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 146.1ms\n",
      "Speed: 3.0ms preprocess, 146.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 132.5ms\n",
      "Speed: 1.7ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.2ms\n",
      "Speed: 2.4ms preprocess, 140.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 145.9ms\n",
      "Speed: 2.0ms preprocess, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 141.5ms\n",
      "Speed: 2.0ms preprocess, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 140.6ms\n",
      "Speed: 4.2ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 146.6ms\n",
      "Speed: 0.0ms preprocess, 146.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 143.0ms\n",
      "Speed: 0.0ms preprocess, 143.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 145.8ms\n",
      "Speed: 0.0ms preprocess, 145.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 137.8ms\n",
      "Speed: 3.1ms preprocess, 137.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 156.7ms\n",
      "Speed: 3.5ms preprocess, 156.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 116.8ms\n",
      "Speed: 3.8ms preprocess, 116.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 126.0ms\n",
      "Speed: 4.0ms preprocess, 126.0ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 143.0ms\n",
      "Speed: 3.4ms preprocess, 143.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 139.9ms\n",
      "Speed: 0.0ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 131.8ms\n",
      "Speed: 3.0ms preprocess, 131.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 134.7ms\n",
      "Speed: 3.4ms preprocess, 134.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 130.9ms\n",
      "Speed: 3.0ms preprocess, 130.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 144.6ms\n",
      "Speed: 3.0ms preprocess, 144.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 139.4ms\n",
      "Speed: 4.0ms preprocess, 139.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 133.0ms\n",
      "Speed: 0.0ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 142.9ms\n",
      "Speed: 4.6ms preprocess, 142.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 140.1ms\n",
      "Speed: 2.5ms preprocess, 140.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 136.2ms\n",
      "Speed: 0.0ms preprocess, 136.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 140.7ms\n",
      "Speed: 3.6ms preprocess, 140.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 149.3ms\n",
      "Speed: 0.0ms preprocess, 149.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 136.1ms\n",
      "Speed: 3.0ms preprocess, 136.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 129.6ms\n",
      "Speed: 0.0ms preprocess, 129.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 139.6ms\n",
      "Speed: 4.1ms preprocess, 139.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 157.1ms\n",
      "Speed: 3.5ms preprocess, 157.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 137.8ms\n",
      "Speed: 3.6ms preprocess, 137.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 145.8ms\n",
      "Speed: 4.1ms preprocess, 145.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 149.0ms\n",
      "Speed: 0.0ms preprocess, 149.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Faces, 141.7ms\n",
      "Speed: 3.2ms preprocess, 141.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.7ms\n",
      "Speed: 2.0ms preprocess, 135.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 143.4ms\n",
      "Speed: 2.3ms preprocess, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 150.9ms\n",
      "Speed: 0.0ms preprocess, 150.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 132.5ms\n",
      "Speed: 2.0ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 138.1ms\n",
      "Speed: 3.3ms preprocess, 138.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 145.5ms\n",
      "Speed: 3.0ms preprocess, 145.5ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 145.0ms\n",
      "Speed: 2.2ms preprocess, 145.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 139.7ms\n",
      "Speed: 0.0ms preprocess, 139.7ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 150.5ms\n",
      "Speed: 2.2ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 152.1ms\n",
      "Speed: 4.4ms preprocess, 152.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 152.7ms\n",
      "Speed: 0.0ms preprocess, 152.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 121.8ms\n",
      "Speed: 2.0ms preprocess, 121.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 141.9ms\n",
      "Speed: 2.5ms preprocess, 141.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 142.4ms\n",
      "Speed: 0.0ms preprocess, 142.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 142.0ms\n",
      "Speed: 4.1ms preprocess, 142.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 143.2ms\n",
      "Speed: 4.0ms preprocess, 143.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 141.5ms\n",
      "Speed: 3.4ms preprocess, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 141.2ms\n",
      "Speed: 1.6ms preprocess, 141.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 137.6ms\n",
      "Speed: 2.0ms preprocess, 137.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 142.3ms\n",
      "Speed: 3.0ms preprocess, 142.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 135.5ms\n",
      "Speed: 2.2ms preprocess, 135.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 134.0ms\n",
      "Speed: 1.8ms preprocess, 134.0ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 133.1ms\n",
      "Speed: 2.3ms preprocess, 133.1ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 148.6ms\n",
      "Speed: 3.0ms preprocess, 148.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 157.0ms\n",
      "Speed: 0.0ms preprocess, 157.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 138.4ms\n",
      "Speed: 4.8ms preprocess, 138.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 144.6ms\n",
      "Speed: 4.0ms preprocess, 144.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 124.6ms\n",
      "Speed: 2.5ms preprocess, 124.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 139.8ms\n",
      "Speed: 0.0ms preprocess, 139.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 137.6ms\n",
      "Speed: 2.2ms preprocess, 137.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 127.9ms\n",
      "Speed: 5.0ms preprocess, 127.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 138.7ms\n",
      "Speed: 3.2ms preprocess, 138.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 131.4ms\n",
      "Speed: 3.1ms preprocess, 131.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 128.9ms\n",
      "Speed: 3.0ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 133.5ms\n",
      "Speed: 2.0ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 142.7ms\n",
      "Speed: 4.1ms preprocess, 142.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 138.5ms\n",
      "Speed: 0.0ms preprocess, 138.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 114.2ms\n",
      "Speed: 3.9ms preprocess, 114.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 144.5ms\n",
      "Speed: 3.0ms preprocess, 144.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 149.0ms\n",
      "Speed: 2.6ms preprocess, 149.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 139.8ms\n",
      "Speed: 5.3ms preprocess, 139.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 143.7ms\n",
      "Speed: 3.4ms preprocess, 143.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 129.7ms\n",
      "Speed: 2.5ms preprocess, 129.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Face, 125.2ms\n",
      "Speed: 2.6ms preprocess, 125.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 145.1ms\n",
      "Speed: 2.0ms preprocess, 145.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 146.3ms\n",
      "Speed: 1.2ms preprocess, 146.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 1 Face, 142.2ms\n",
      "Speed: 0.0ms preprocess, 142.2ms inference, 0.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 143.6ms\n",
      "Speed: 3.1ms preprocess, 143.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 142.1ms\n",
      "Speed: 3.1ms preprocess, 142.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 127.0ms\n",
      "Speed: 3.0ms preprocess, 127.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 144.1ms\n",
      "Speed: 2.0ms preprocess, 144.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 133.1ms\n",
      "Speed: 0.0ms preprocess, 133.1ms inference, 15.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.9ms\n",
      "Speed: 3.7ms preprocess, 135.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 150.2ms\n",
      "Speed: 4.0ms preprocess, 150.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 148.8ms\n",
      "Speed: 2.4ms preprocess, 148.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 146.0ms\n",
      "Speed: 2.0ms preprocess, 146.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 145.6ms\n",
      "Speed: 0.0ms preprocess, 145.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 128.2ms\n",
      "Speed: 4.3ms preprocess, 128.2ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 128.2ms\n",
      "Speed: 5.5ms preprocess, 128.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 137.8ms\n",
      "Speed: 0.0ms preprocess, 137.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 130.0ms\n",
      "Speed: 2.0ms preprocess, 130.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 143.4ms\n",
      "Speed: 3.6ms preprocess, 143.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.9ms\n",
      "Speed: 2.0ms preprocess, 135.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 133.0ms\n",
      "Speed: 2.8ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 128.2ms\n",
      "Speed: 3.3ms preprocess, 128.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 130.1ms\n",
      "Speed: 2.9ms preprocess, 130.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.5ms\n",
      "Speed: 3.4ms preprocess, 134.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.0ms\n",
      "Speed: 0.0ms preprocess, 134.0ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 139.9ms\n",
      "Speed: 1.7ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 149.0ms\n",
      "Speed: 2.1ms preprocess, 149.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 120.3ms\n",
      "Speed: 4.0ms preprocess, 120.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 149.0ms\n",
      "Speed: 2.2ms preprocess, 149.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 137.7ms\n",
      "Speed: 0.0ms preprocess, 137.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.2ms\n",
      "Speed: 3.1ms preprocess, 134.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 139.8ms\n",
      "Speed: 6.8ms preprocess, 139.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.9ms\n",
      "Speed: 2.8ms preprocess, 135.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 141.7ms\n",
      "Speed: 0.0ms preprocess, 141.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.1ms\n",
      "Speed: 2.0ms preprocess, 135.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 137.4ms\n",
      "Speed: 3.8ms preprocess, 137.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 135.5ms\n",
      "Speed: 4.1ms preprocess, 135.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 125.2ms\n",
      "Speed: 1.7ms preprocess, 125.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 144.8ms\n",
      "Speed: 6.6ms preprocess, 144.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 145.5ms\n",
      "Speed: 5.7ms preprocess, 145.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 129.5ms\n",
      "Speed: 3.5ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 134.6ms\n",
      "Speed: 3.0ms preprocess, 134.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 139.7ms\n",
      "Speed: 0.0ms preprocess, 139.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 151.2ms\n",
      "Speed: 2.0ms preprocess, 151.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 Faces, 159.1ms\n",
      "Speed: 3.0ms preprocess, 159.1ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 152.1ms\n",
      "Speed: 5.0ms preprocess, 152.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 160.2ms\n",
      "Speed: 6.0ms preprocess, 160.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 151.5ms\n",
      "Speed: 3.0ms preprocess, 151.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 164.5ms\n",
      "Speed: 1.8ms preprocess, 164.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 152.1ms\n",
      "Speed: 3.5ms preprocess, 152.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 150.4ms\n",
      "Speed: 1.6ms preprocess, 150.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 160.8ms\n",
      "Speed: 2.8ms preprocess, 160.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.0ms\n",
      "Speed: 3.0ms preprocess, 140.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 141.7ms\n",
      "Speed: 4.3ms preprocess, 141.7ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 140.0ms\n",
      "Speed: 2.2ms preprocess, 140.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 169.1ms\n",
      "Speed: 15.4ms preprocess, 169.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 167.8ms\n",
      "Speed: 0.0ms preprocess, 167.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 159.0ms\n",
      "Speed: 3.0ms preprocess, 159.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 163.8ms\n",
      "Speed: 3.2ms preprocess, 163.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 157.5ms\n",
      "Speed: 3.0ms preprocess, 157.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 147.9ms\n",
      "Speed: 2.2ms preprocess, 147.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 152.5ms\n",
      "Speed: 3.0ms preprocess, 152.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 139.5ms\n",
      "Speed: 4.0ms preprocess, 139.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 149.0ms\n",
      "Speed: 3.0ms preprocess, 149.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 154.1ms\n",
      "Speed: 4.0ms preprocess, 154.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 159.3ms\n",
      "Speed: 4.0ms preprocess, 159.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 131.2ms\n",
      "Speed: 1.2ms preprocess, 131.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 127.5ms\n",
      "Speed: 3.0ms preprocess, 127.5ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 138.1ms\n",
      "Speed: 4.6ms preprocess, 138.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 153.4ms\n",
      "Speed: 4.0ms preprocess, 153.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 146.6ms\n",
      "Speed: 3.0ms preprocess, 146.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 172.9ms\n",
      "Speed: 0.0ms preprocess, 172.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 179.8ms\n",
      "Speed: 1.0ms preprocess, 179.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 179.0ms\n",
      "Speed: 3.0ms preprocess, 179.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 180.3ms\n",
      "Speed: 2.0ms preprocess, 180.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 180.6ms\n",
      "Speed: 3.0ms preprocess, 180.6ms inference, 16.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 183.7ms\n",
      "Speed: 0.0ms preprocess, 183.7ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 172.2ms\n",
      "Speed: 4.7ms preprocess, 172.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 193.9ms\n",
      "Speed: 3.0ms preprocess, 193.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n",
      "0: 480x640 2 Faces, 177.4ms\n",
      "Speed: 1.8ms preprocess, 177.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\predict4\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m success,frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m---> 18\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     annotate_frame \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m     22\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOLO8 Interface\u001b[39m\u001b[38;5;124m\"\u001b[39m,annotate_frame)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\model.py:96\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\model.py:236\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\predictor.py:194\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\predictor.py:253\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 253\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\predictor.py:133\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minference\u001b[39m(\u001b[38;5;28mself\u001b[39m, im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    131\u001b[0m     visualize \u001b[38;5;241m=\u001b[39m increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem,\n\u001b[0;32m    132\u001b[0m                                mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:333\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize)\u001b[0m\n\u001b[0;32m    330\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize) \u001b[38;5;28;01mif\u001b[39;00m augment \u001b[38;5;129;01mor\u001b[39;00m visualize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m---> 82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m     83\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:134\u001b[0m, in \u001b[0;36mSPPF.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    132\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm(x)\n\u001b[0;32m    133\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm(y1)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat((x, y1, y2, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my2\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt')  # load a custom model\n",
    "\n",
    "# Open the video file\n",
    "video_path = 0\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# loop through video frame\n",
    "while cap.isOpened():\n",
    "    success,frame = cap.read()\n",
    "    \n",
    "    if success:\n",
    "        result = model(frame, save=True)\n",
    "        \n",
    "        annotate_frame = result[0].plot()\n",
    "        \n",
    "        cv2.imshow(\"YOLO8 Interface\",annotate_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fce665",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.10.9 torch-2.0.1+cpu CPU (Intel Core(TM) i5-8365U 1.60GHz)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx', 'onnx2tf>=1.15.4', 'sng4onnx>=1.0.1', 'onnxsim>=0.4.33', 'onnx_graphsurgeon>=0.3.26', 'tflite_support', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting onnx\n",
      "  Obtaining dependency information for onnx from https://files.pythonhosted.org/packages/00/36/e7a7e7a85564e7d409e4e8addfa11d41015d2190bfff30064771e7c21ca0/onnx-1.14.1-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading onnx-1.14.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting onnx2tf>=1.15.4\n",
      "  Obtaining dependency information for onnx2tf>=1.15.4 from https://files.pythonhosted.org/packages/43/a9/3ae61c813158ca5b41459ddf56e18405a0f3b1d51fc452fea63d0d0c1bb5/onnx2tf-1.16.28-py3-none-any.whl.metadata\n",
      "  Downloading onnx2tf-1.16.28-py3-none-any.whl.metadata (126 kB)\n",
      "     -------------------------------------- 126.9/126.9 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting sng4onnx>=1.0.1\n",
      "  Downloading sng4onnx-1.0.1-py3-none-any.whl (5.8 kB)\n",
      "Collecting onnxsim>=0.4.33\n",
      "  Obtaining dependency information for onnxsim>=0.4.33 from https://files.pythonhosted.org/packages/1d/b0/69a28a9f762d16d1f7e1e8d7f3d37f15f5fb05ab33e92a9974012e3598ce/onnxsim-0.4.33-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading onnxsim-0.4.33-cp310-cp310-win_amd64.whl.metadata (4.4 kB)\n",
      "Collecting onnx_graphsurgeon>=0.3.26\n",
      "  Downloading https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.1/42.1 kB ? eta 0:00:00\n",
      "Collecting tflite_support\n",
      "  Downloading tflite-support-0.1.0a1.tar.gz (390 kB)\n",
      "     -------------------------------------- 390.3/390.3 kB 6.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting onnxruntime\n",
      "  Obtaining dependency information for onnxruntime from https://files.pythonhosted.org/packages/aa/2a/9d7edd7a329a7f34e25af60a1e47468cbc864766898c7b9d3b540d0f1539/onnxruntime-1.15.1-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading onnxruntime-1.15.1-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from onnx) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from onnx) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from onnx) (4.7.1)\n",
      "Collecting rich (from onnxsim>=0.4.33)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/c1/d1/23ba6235ed82883bb416f57179d1db2c05f3fb8e5d83c18660f9ab6f09c9/rich-13.5.3-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.5.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pybind11>=2.4 (from tflite_support)\n",
      "  Obtaining dependency information for pybind11>=2.4 from https://files.pythonhosted.org/packages/06/55/9f73c32dda93fa4f539fafa268f9504e83c489f460c380371d94296126cd/pybind11-2.11.1-py3-none-any.whl.metadata\n",
      "  Downloading pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from tflite_support) (1.4.0)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: packaging in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from onnxruntime) (23.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from onnxruntime) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB ? eta 0:00:00\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->onnxsim>=0.4.33)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from rich->onnxsim>=0.4.33) (2.15.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB ? eta 0:00:00\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->onnxsim>=0.4.33)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading onnx-1.14.1-cp310-cp310-win_amd64.whl (13.3 MB)\n",
      "   ---------------------------------------- 13.3/13.3 MB 34.4 MB/s eta 0:00:00\n",
      "Downloading onnx2tf-1.16.28-py3-none-any.whl (399 kB)\n",
      "   ---------------------------------------- 399.0/399.0 kB ? eta 0:00:00\n",
      "Downloading onnxsim-0.4.33-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 1.2/1.2 MB 39.7 MB/s eta 0:00:00\n",
      "Downloading onnxruntime-1.15.1-cp310-cp310-win_amd64.whl (6.7 MB)\n",
      "   ---------------------------------------- 6.7/6.7 MB 48.1 MB/s eta 0:00:00\n",
      "Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 227.7/227.7 kB ? eta 0:00:00\n",
      "Downloading rich-13.5.3-py3-none-any.whl (239 kB)\n",
      "   --------------------------------------- 239.8/239.8 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 87.5/87.5 kB 4.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: tflite_support\n",
      "  Building wheel for tflite_support (setup.py): started\n",
      "  Building wheel for tflite_support (setup.py): finished with status 'done'\n",
      "  Created wheel for tflite_support: filename=tflite_support-0.1.0a1-cp310-cp310-win_amd64.whl size=358904 sha256=0443b24f38b5b5098d728d61b0fe94a90ad13ac76913056836d621cd53df2ad3\n",
      "  Stored in directory: C:\\Users\\BAPS\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-kavrjrhs\\wheels\\71\\5c\\da\\9e5e661ec26e03ee57e69428d40fffbefe3c0aff649c55776d\n",
      "Successfully built tflite_support\n",
      "Installing collected packages: pyreadline3, sng4onnx, pybind11, onnx2tf, onnx, mdurl, humanfriendly, tflite_support, onnx_graphsurgeon, markdown-it-py, coloredlogs, rich, onnxruntime, onnxsim\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 markdown-it-py-3.0.0 mdurl-0.1.2 onnx-1.14.1 onnx2tf-1.16.28 onnx_graphsurgeon-0.3.27 onnxruntime-1.15.1 onnxsim-0.4.33 pybind11-2.11.1 pyreadline3-3.4.1 rich-13.5.3 sng4onnx-1.0.1 tflite_support-0.1.0a1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  72.6s, installed 7 packages: ['onnx', 'onnx2tf>=1.15.4', 'sng4onnx>=1.0.1', 'onnxsim>=0.4.33', 'onnx_graphsurgeon>=0.3.26', 'tflite_support', 'onnxruntime']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.12.0...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  6.3s, saved as 'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.onnx' (11.6 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i \"C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.onnx\" -o \"C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best_saved_model\" -nuo --non_verbose'\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  102.4s, saved as 'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best_saved_model' (29.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.12.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success  0.0s, saved as 'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best_saved_model\\best_float32.tflite' (11.6 MB)\n",
      "\n",
      "Export complete (104.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\detect\\train\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best_saved_model\\best_float32.tflite imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best_saved_model\\best_float32.tflite imgsz=640 data=D:/Face Detection_yolov8/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\BAPS\\\\runs\\\\detect\\\\train\\\\weights\\\\best_saved_model\\\\best_float32.tflite'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')  # load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt')  # load a custom trained\n",
    "\n",
    "# Export the model\n",
    "model.export(format='tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442857ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "cap = cv.VideoCapture(0)\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detector:\n",
    "    frame_counter = 0\n",
    "    fonts = cv.FONT_HERSHEY_PLAIN\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        frame_counter += 1\n",
    "        ret, frame = cap.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        results = face_detector.process(rgb_frame)\n",
    "        frame_height, frame_width, c = frame.shape\n",
    "        if results.detections:\n",
    "            for face in results.detections:\n",
    "                face_react = np.multiply(\n",
    "                    [\n",
    "                        face.location_data.relative_bounding_box.xmin,\n",
    "                        face.location_data.relative_bounding_box.ymin,\n",
    "                        face.location_data.relative_bounding_box.width,\n",
    "                        face.location_data.relative_bounding_box.height,\n",
    "                    ],\n",
    "                    [frame_width, frame_height, frame_width, frame_height]).astype(int)\n",
    "                \n",
    "                cv.rectangle(frame, face_react, color=(255, 255, 255), thickness=2)\n",
    "                key_points = np.array([(p.x, p.y) for p in face.location_data.relative_keypoints])\n",
    "                key_points_coords = np.multiply(key_points,[frame_width,frame_height]).astype(int)\n",
    "                for p in key_points_coords:\n",
    "                    cv.circle(frame, p, 4, (255, 255, 255), 2)\n",
    "                    cv.circle(frame, p, 2, (0, 0, 0), -1)\n",
    "        \n",
    "        fps = frame_counter / (time.time() - start_time)\n",
    "        cv.putText(frame,f\"FPS: {fps:.2f}\",(30, 30),cv.FONT_HERSHEY_DUPLEX,0.7,(0, 255, 255),2,)\n",
    "        cv.imshow(\"frame\", frame)\n",
    "        key = cv.waitKey(1)\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa38c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Face, 257.2ms\n",
      "Speed: 6.9ms preprocess, 257.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.5ms\n",
      "Speed: 5.0ms preprocess, 205.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 211.7ms\n",
      "Speed: 3.4ms preprocess, 211.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.9ms\n",
      "Speed: 0.5ms preprocess, 191.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.1ms\n",
      "Speed: 3.0ms preprocess, 185.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 230.7ms\n",
      "Speed: 3.0ms preprocess, 230.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.6ms\n",
      "Speed: 1.7ms preprocess, 156.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.6ms\n",
      "Speed: 3.2ms preprocess, 134.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 133.0ms\n",
      "Speed: 2.8ms preprocess, 133.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.8ms\n",
      "Speed: 2.6ms preprocess, 134.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.4ms\n",
      "Speed: 3.6ms preprocess, 138.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 131.4ms\n",
      "Speed: 5.0ms preprocess, 131.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 137.1ms\n",
      "Speed: 2.3ms preprocess, 137.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 123.3ms\n",
      "Speed: 3.0ms preprocess, 123.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.5ms\n",
      "Speed: 5.1ms preprocess, 129.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.7ms\n",
      "Speed: 3.9ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 124.8ms\n",
      "Speed: 3.1ms preprocess, 124.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 136.4ms\n",
      "Speed: 3.5ms preprocess, 136.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 128.3ms\n",
      "Speed: 1.5ms preprocess, 128.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 137.1ms\n",
      "Speed: 2.2ms preprocess, 137.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 128.4ms\n",
      "Speed: 2.0ms preprocess, 128.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.7ms\n",
      "Speed: 2.3ms preprocess, 129.7ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 108.5ms\n",
      "Speed: 2.5ms preprocess, 108.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 106.0ms\n",
      "Speed: 2.3ms preprocess, 106.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 122.2ms\n",
      "Speed: 2.0ms preprocess, 122.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 125.7ms\n",
      "Speed: 1.9ms preprocess, 125.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 127.2ms\n",
      "Speed: 2.0ms preprocess, 127.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 126.9ms\n",
      "Speed: 2.2ms preprocess, 126.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.4ms\n",
      "Speed: 2.6ms preprocess, 134.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 124.7ms\n",
      "Speed: 2.6ms preprocess, 124.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 128.3ms\n",
      "Speed: 4.0ms preprocess, 128.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 128.9ms\n",
      "Speed: 2.6ms preprocess, 128.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 131.1ms\n",
      "Speed: 2.2ms preprocess, 131.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.8ms\n",
      "Speed: 2.0ms preprocess, 134.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.0ms\n",
      "Speed: 3.4ms preprocess, 129.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 131.7ms\n",
      "Speed: 3.0ms preprocess, 131.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 121.8ms\n",
      "Speed: 3.0ms preprocess, 121.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 118.4ms\n",
      "Speed: 2.8ms preprocess, 118.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 121.5ms\n",
      "Speed: 2.0ms preprocess, 121.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 121.5ms\n",
      "Speed: 3.9ms preprocess, 121.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 145.3ms\n",
      "Speed: 0.0ms preprocess, 145.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 153.8ms\n",
      "Speed: 1.7ms preprocess, 153.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 150.0ms\n",
      "Speed: 3.1ms preprocess, 150.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 146.6ms\n",
      "Speed: 3.6ms preprocess, 146.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 150.2ms\n",
      "Speed: 2.6ms preprocess, 150.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.2ms\n",
      "Speed: 4.4ms preprocess, 173.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 246.8ms\n",
      "Speed: 10.0ms preprocess, 246.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 141.1ms\n",
      "Speed: 3.7ms preprocess, 141.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 121.8ms\n",
      "Speed: 3.4ms preprocess, 121.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 123.0ms\n",
      "Speed: 1.7ms preprocess, 123.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 124.9ms\n",
      "Speed: 2.0ms preprocess, 124.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 119.9ms\n",
      "Speed: 2.1ms preprocess, 119.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 123.2ms\n",
      "Speed: 3.5ms preprocess, 123.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 150.6ms\n",
      "Speed: 0.0ms preprocess, 150.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 167.3ms\n",
      "Speed: 1.3ms preprocess, 167.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 151.7ms\n",
      "Speed: 2.7ms preprocess, 151.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 139.2ms\n",
      "Speed: 3.0ms preprocess, 139.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 136.5ms\n",
      "Speed: 2.7ms preprocess, 136.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 133.3ms\n",
      "Speed: 3.2ms preprocess, 133.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 131.2ms\n",
      "Speed: 2.2ms preprocess, 131.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 125.9ms\n",
      "Speed: 2.1ms preprocess, 125.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 118.6ms\n",
      "Speed: 9.0ms preprocess, 118.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 140.7ms\n",
      "Speed: 1.4ms preprocess, 140.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 133.6ms\n",
      "Speed: 2.4ms preprocess, 133.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 135.9ms\n",
      "Speed: 3.0ms preprocess, 135.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 122.9ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.3ms preprocess, 122.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.8ms\n",
      "Speed: 2.7ms preprocess, 129.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.3ms\n",
      "Speed: 3.4ms preprocess, 134.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 122.4ms\n",
      "Speed: 2.4ms preprocess, 122.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.9ms\n",
      "Speed: 3.4ms preprocess, 134.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 114.3ms\n",
      "Speed: 2.4ms preprocess, 114.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 118.2ms\n",
      "Speed: 2.3ms preprocess, 118.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 116.5ms\n",
      "Speed: 3.6ms preprocess, 116.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 120.5ms\n",
      "Speed: 2.2ms preprocess, 120.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 108.1ms\n",
      "Speed: 2.1ms preprocess, 108.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.7ms\n",
      "Speed: 2.1ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 119.5ms\n",
      "Speed: 2.6ms preprocess, 119.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 121.3ms\n",
      "Speed: 2.3ms preprocess, 121.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 125.6ms\n",
      "Speed: 2.0ms preprocess, 125.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 130.6ms\n",
      "Speed: 2.0ms preprocess, 130.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 131.7ms\n",
      "Speed: 1.0ms preprocess, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 137.5ms\n",
      "Speed: 2.5ms preprocess, 137.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.1ms\n",
      "Speed: 1.6ms preprocess, 129.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 127.3ms\n",
      "Speed: 3.7ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 122.5ms\n",
      "Speed: 1.7ms preprocess, 122.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.5ms\n",
      "Speed: 1.9ms preprocess, 134.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 128.7ms\n",
      "Speed: 3.4ms preprocess, 128.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.5ms\n",
      "Speed: 2.2ms preprocess, 156.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 150.5ms\n",
      "Speed: 4.6ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.3ms\n",
      "Speed: 3.1ms preprocess, 148.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.3ms\n",
      "Speed: 4.4ms preprocess, 170.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 146.0ms\n",
      "Speed: 2.4ms preprocess, 146.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 143.9ms\n",
      "Speed: 2.6ms preprocess, 143.9ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 130.8ms\n",
      "Speed: 2.3ms preprocess, 130.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 117.0ms\n",
      "Speed: 2.0ms preprocess, 117.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 119.0ms\n",
      "Speed: 0.0ms preprocess, 119.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 143.9ms\n",
      "Speed: 2.3ms preprocess, 143.9ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 147.2ms\n",
      "Speed: 0.0ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.3ms\n",
      "Speed: 4.0ms preprocess, 158.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.1ms\n",
      "Speed: 2.0ms preprocess, 148.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 141.0ms\n",
      "Speed: 3.3ms preprocess, 141.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 143.5ms\n",
      "Speed: 2.0ms preprocess, 143.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 123.6ms\n",
      "Speed: 2.0ms preprocess, 123.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 117.0ms\n",
      "Speed: 1.6ms preprocess, 117.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 125.8ms\n",
      "Speed: 2.0ms preprocess, 125.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.2ms\n",
      "Speed: 3.0ms preprocess, 138.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.7ms\n",
      "Speed: 3.0ms preprocess, 134.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 122.6ms\n",
      "Speed: 4.5ms preprocess, 122.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 123.7ms\n",
      "Speed: 2.0ms preprocess, 123.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 121.8ms\n",
      "Speed: 1.7ms preprocess, 121.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 135.6ms\n",
      "Speed: 3.0ms preprocess, 135.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 133.8ms\n",
      "Speed: 2.9ms preprocess, 133.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 142.6ms\n",
      "Speed: 2.0ms preprocess, 142.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.2ms\n",
      "Speed: 1.6ms preprocess, 138.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 136.4ms\n",
      "Speed: 2.7ms preprocess, 136.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 130.2ms\n",
      "Speed: 3.3ms preprocess, 130.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 121.8ms\n",
      "Speed: 2.0ms preprocess, 121.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 152.6ms\n",
      "Speed: 3.0ms preprocess, 152.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.8ms\n",
      "Speed: 3.3ms preprocess, 148.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 132.8ms\n",
      "Speed: 3.2ms preprocess, 132.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 125.4ms\n",
      "Speed: 3.0ms preprocess, 125.4ms inference, 11.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.4ms\n",
      "Speed: 3.8ms preprocess, 138.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 142.0ms\n",
      "Speed: 1.6ms preprocess, 142.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 137.5ms\n",
      "Speed: 3.3ms preprocess, 137.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.1ms\n",
      "Speed: 1.7ms preprocess, 138.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 119.4ms\n",
      "Speed: 3.3ms preprocess, 119.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 122.5ms\n",
      "Speed: 2.5ms preprocess, 122.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 134.1ms\n",
      "Speed: 2.0ms preprocess, 134.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 136.1ms\n",
      "Speed: 2.9ms preprocess, 136.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 126.8ms\n",
      "Speed: 2.0ms preprocess, 126.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.8ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.8ms preprocess, 129.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 136.3ms\n",
      "Speed: 0.0ms preprocess, 136.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 126.1ms\n",
      "Speed: 2.0ms preprocess, 126.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 140.7ms\n",
      "Speed: 4.1ms preprocess, 140.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.7ms\n",
      "Speed: 2.5ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 124.9ms\n",
      "Speed: 0.0ms preprocess, 124.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 132.2ms\n",
      "Speed: 1.7ms preprocess, 132.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.1ms\n",
      "Speed: 2.0ms preprocess, 138.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 135.1ms\n",
      "Speed: 1.7ms preprocess, 135.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 145.9ms\n",
      "Speed: 4.7ms preprocess, 145.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 132.5ms\n",
      "Speed: 2.0ms preprocess, 132.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 135.1ms\n",
      "Speed: 1.7ms preprocess, 135.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 131.4ms\n",
      "Speed: 2.6ms preprocess, 131.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 143.1ms\n",
      "Speed: 2.0ms preprocess, 143.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 146.3ms\n",
      "Speed: 0.0ms preprocess, 146.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 124.0ms\n",
      "Speed: 2.0ms preprocess, 124.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 133.6ms\n",
      "Speed: 1.7ms preprocess, 133.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 125.4ms\n",
      "Speed: 2.3ms preprocess, 125.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 113.2ms\n",
      "Speed: 2.3ms preprocess, 113.2ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 137.7ms\n",
      "Speed: 2.0ms preprocess, 137.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 126.2ms\n",
      "Speed: 0.0ms preprocess, 126.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 120.6ms\n",
      "Speed: 3.1ms preprocess, 120.6ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 119.8ms\n",
      "Speed: 1.8ms preprocess, 119.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 130.0ms\n",
      "Speed: 0.0ms preprocess, 130.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 119.6ms\n",
      "Speed: 2.3ms preprocess, 119.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 137.3ms\n",
      "Speed: 0.0ms preprocess, 137.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.0ms\n",
      "Speed: 0.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 121.7ms\n",
      "Speed: 1.7ms preprocess, 121.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 137.5ms\n",
      "Speed: 0.0ms preprocess, 137.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 120.5ms\n",
      "Speed: 2.0ms preprocess, 120.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 139.6ms\n",
      "Speed: 2.5ms preprocess, 139.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 142.0ms\n",
      "Speed: 1.7ms preprocess, 142.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 128.8ms\n",
      "Speed: 2.0ms preprocess, 128.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 125.9ms\n",
      "Speed: 3.8ms preprocess, 125.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 140.8ms\n",
      "Speed: 1.6ms preprocess, 140.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 122.0ms\n",
      "Speed: 2.8ms preprocess, 122.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 151.7ms\n",
      "Speed: 2.0ms preprocess, 151.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.4ms\n",
      "Speed: 3.1ms preprocess, 156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.9ms\n",
      "Speed: 2.6ms preprocess, 156.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.4ms\n",
      "Speed: 2.0ms preprocess, 166.4ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.4ms\n",
      "Speed: 3.7ms preprocess, 168.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.9ms\n",
      "Speed: 2.4ms preprocess, 172.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 151.0ms\n",
      "Speed: 2.2ms preprocess, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 137.4ms\n",
      "Speed: 0.0ms preprocess, 137.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 122.0ms\n",
      "Speed: 3.1ms preprocess, 122.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 157.7ms\n",
      "Speed: 0.0ms preprocess, 157.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.9ms\n",
      "Speed: 0.0ms preprocess, 158.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 159.4ms\n",
      "Speed: 1.7ms preprocess, 159.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 130.9ms\n",
      "Speed: 2.5ms preprocess, 130.9ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 155.2ms\n",
      "Speed: 1.6ms preprocess, 155.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.4ms\n",
      "Speed: 2.8ms preprocess, 154.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.5ms\n",
      "Speed: 1.7ms preprocess, 156.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 155.1ms\n",
      "Speed: 3.8ms preprocess, 155.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 142.6ms\n",
      "Speed: 0.0ms preprocess, 142.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.9ms\n",
      "Speed: 2.7ms preprocess, 185.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.7ms\n",
      "Speed: 1.9ms preprocess, 177.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.0ms\n",
      "Speed: 3.6ms preprocess, 170.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.4ms\n",
      "Speed: 3.1ms preprocess, 188.4ms inference, 13.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 153.4ms\n",
      "Speed: 4.0ms preprocess, 153.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 157.9ms\n",
      "Speed: 0.0ms preprocess, 157.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.6ms\n",
      "Speed: 3.1ms preprocess, 169.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 162.2ms\n",
      "Speed: 3.9ms preprocess, 162.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 155.3ms\n",
      "Speed: 2.8ms preprocess, 155.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 142.9ms\n",
      "Speed: 3.7ms preprocess, 142.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 151.7ms\n",
      "Speed: 0.0ms preprocess, 151.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 147.9ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.5ms preprocess, 147.9ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 152.1ms\n",
      "Speed: 2.5ms preprocess, 152.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 141.6ms\n",
      "Speed: 3.3ms preprocess, 141.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 150.8ms\n",
      "Speed: 3.1ms preprocess, 150.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 145.8ms\n",
      "Speed: 4.0ms preprocess, 145.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 219.0ms\n",
      "Speed: 2.9ms preprocess, 219.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.5ms\n",
      "Speed: 4.2ms preprocess, 138.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.9ms\n",
      "Speed: 2.8ms preprocess, 154.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 155.4ms\n",
      "Speed: 2.2ms preprocess, 155.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.5ms\n",
      "Speed: 0.0ms preprocess, 158.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.5ms\n",
      "Speed: 0.0ms preprocess, 158.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 164.3ms\n",
      "Speed: 23.5ms preprocess, 164.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 150.9ms\n",
      "Speed: 1.8ms preprocess, 150.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 139.5ms\n",
      "Speed: 2.8ms preprocess, 139.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.4ms\n",
      "Speed: 0.0ms preprocess, 148.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 149.9ms\n",
      "Speed: 0.0ms preprocess, 149.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 149.5ms\n",
      "Speed: 0.0ms preprocess, 149.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.8ms\n",
      "Speed: 1.6ms preprocess, 165.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.8ms\n",
      "Speed: 0.0ms preprocess, 188.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 157.0ms\n",
      "Speed: 0.0ms preprocess, 157.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 141.7ms\n",
      "Speed: 0.0ms preprocess, 141.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.2ms\n",
      "Speed: 0.0ms preprocess, 158.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 178.9ms\n",
      "Speed: 0.0ms preprocess, 178.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 152.1ms\n",
      "Speed: 6.4ms preprocess, 152.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 160.0ms\n",
      "Speed: 0.0ms preprocess, 160.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 139.4ms\n",
      "Speed: 2.8ms preprocess, 139.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 129.7ms\n",
      "Speed: 1.8ms preprocess, 129.7ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 140.8ms\n",
      "Speed: 1.7ms preprocess, 140.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 142.5ms\n",
      "Speed: 0.0ms preprocess, 142.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 171.2ms\n",
      "Speed: 3.0ms preprocess, 171.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 143.0ms\n",
      "Speed: 0.0ms preprocess, 143.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 140.0ms\n",
      "Speed: 3.6ms preprocess, 140.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 144.2ms\n",
      "Speed: 1.8ms preprocess, 144.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.8ms\n",
      "Speed: 0.0ms preprocess, 148.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 142.2ms\n",
      "Speed: 0.0ms preprocess, 142.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 146.1ms\n",
      "Speed: 0.0ms preprocess, 146.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.7ms\n",
      "Speed: 0.0ms preprocess, 173.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.7ms\n",
      "Speed: 0.0ms preprocess, 193.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 206.7ms\n",
      "Speed: 1.4ms preprocess, 206.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.6ms\n",
      "Speed: 5.0ms preprocess, 183.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 181.0ms\n",
      "Speed: 0.0ms preprocess, 181.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 218.8ms\n",
      "Speed: 0.0ms preprocess, 218.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 208.6ms\n",
      "Speed: 0.0ms preprocess, 208.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 209.9ms\n",
      "Speed: 0.0ms preprocess, 209.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.4ms\n",
      "Speed: 3.5ms preprocess, 193.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.9ms\n",
      "Speed: 2.4ms preprocess, 202.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 209.0ms\n",
      "Speed: 0.0ms preprocess, 209.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 211.3ms\n",
      "Speed: 0.0ms preprocess, 211.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.3ms\n",
      "Speed: 0.0ms preprocess, 202.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 192.7ms\n",
      "Speed: 0.0ms preprocess, 192.7ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 212.5ms\n",
      "Speed: 2.9ms preprocess, 212.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 208.1ms\n",
      "Speed: 0.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.2ms\n",
      "Speed: 0.0ms preprocess, 202.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.8ms\n",
      "Speed: 7.6ms preprocess, 175.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.8ms\n",
      "Speed: 4.6ms preprocess, 197.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.6ms\n",
      "Speed: 0.0ms preprocess, 203.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 192.3ms\n",
      "Speed: 0.0ms preprocess, 192.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.1ms\n",
      "Speed: 3.7ms preprocess, 199.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.1ms\n",
      "Speed: 0.0ms preprocess, 177.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.3ms\n",
      "Speed: 0.0ms preprocess, 202.3ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.4ms\n",
      "Speed: 0.0ms preprocess, 202.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 222.2ms\n",
      "Speed: 4.0ms preprocess, 222.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.6ms\n",
      "Speed: 2.5ms preprocess, 200.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.6ms\n",
      "Speed: 0.0ms preprocess, 198.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.8ms\n",
      "Speed: 0.0ms preprocess, 202.8ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.5ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.5ms preprocess, 156.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 149.5ms\n",
      "Speed: 2.0ms preprocess, 149.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.0ms\n",
      "Speed: 4.6ms preprocess, 156.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.8ms\n",
      "Speed: 3.0ms preprocess, 197.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.1ms\n",
      "Speed: 0.0ms preprocess, 165.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.5ms\n",
      "Speed: 4.7ms preprocess, 194.5ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.3ms\n",
      "Speed: 0.0ms preprocess, 183.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.7ms\n",
      "Speed: 3.2ms preprocess, 169.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.4ms\n",
      "Speed: 2.0ms preprocess, 185.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.0ms\n",
      "Speed: 0.0ms preprocess, 168.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 146.2ms\n",
      "Speed: 2.0ms preprocess, 146.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 178.8ms\n",
      "Speed: 1.7ms preprocess, 178.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.7ms\n",
      "Speed: 2.0ms preprocess, 193.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.5ms\n",
      "Speed: 3.0ms preprocess, 190.5ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.8ms\n",
      "Speed: 0.0ms preprocess, 199.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.5ms\n",
      "Speed: 0.0ms preprocess, 199.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.3ms\n",
      "Speed: 3.5ms preprocess, 203.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 164.6ms\n",
      "Speed: 0.0ms preprocess, 164.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.4ms\n",
      "Speed: 4.4ms preprocess, 194.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 182.9ms\n",
      "Speed: 3.0ms preprocess, 182.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 178.2ms\n",
      "Speed: 3.3ms preprocess, 178.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.0ms\n",
      "Speed: 3.0ms preprocess, 177.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.9ms\n",
      "Speed: 3.3ms preprocess, 174.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.0ms\n",
      "Speed: 3.5ms preprocess, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 182.1ms\n",
      "Speed: 2.5ms preprocess, 182.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.6ms\n",
      "Speed: 0.0ms preprocess, 199.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 210.4ms\n",
      "Speed: 0.0ms preprocess, 210.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.6ms\n",
      "Speed: 2.8ms preprocess, 170.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.1ms\n",
      "Speed: 2.3ms preprocess, 185.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.9ms\n",
      "Speed: 2.5ms preprocess, 170.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.8ms\n",
      "Speed: 4.1ms preprocess, 185.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 192.0ms\n",
      "Speed: 0.0ms preprocess, 192.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.8ms\n",
      "Speed: 0.0ms preprocess, 158.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.5ms\n",
      "Speed: 2.0ms preprocess, 154.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 143.4ms\n",
      "Speed: 3.0ms preprocess, 143.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.3ms\n",
      "Speed: 4.4ms preprocess, 154.3ms inference, 14.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.1ms\n",
      "Speed: 0.0ms preprocess, 200.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.9ms\n",
      "Speed: 3.0ms preprocess, 177.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.8ms\n",
      "Speed: 0.0ms preprocess, 186.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.8ms\n",
      "Speed: 0.0ms preprocess, 173.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.1ms\n",
      "Speed: 36.4ms preprocess, 196.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 171.2ms\n",
      "Speed: 3.0ms preprocess, 171.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.3ms\n",
      "Speed: 2.5ms preprocess, 190.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.7ms\n",
      "Speed: 2.0ms preprocess, 168.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.8ms\n",
      "Speed: 2.4ms preprocess, 168.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.7ms\n",
      "Speed: 2.2ms preprocess, 161.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.3ms\n",
      "Speed: 4.0ms preprocess, 161.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 162.4ms\n",
      "Speed: 5.0ms preprocess, 162.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 178.2ms\n",
      "Speed: 1.7ms preprocess, 178.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.7ms\n",
      "Speed: 0.0ms preprocess, 174.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 163.9ms\n",
      "Speed: 2.0ms preprocess, 163.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.9ms\n",
      "Speed: 3.3ms preprocess, 165.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 153.7ms\n",
      "Speed: 4.0ms preprocess, 153.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.8ms\n",
      "Speed: 2.0ms preprocess, 173.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 210.9ms\n",
      "Speed: 3.0ms preprocess, 210.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 204.6ms\n",
      "Speed: 3.0ms preprocess, 204.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 192.1ms\n",
      "Speed: 4.5ms preprocess, 192.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.4ms\n",
      "Speed: 0.0ms preprocess, 173.4ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 171.4ms\n",
      "Speed: 3.1ms preprocess, 171.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 159.5ms\n",
      "Speed: 3.0ms preprocess, 159.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.9ms\n",
      "Speed: 0.0ms preprocess, 198.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.9ms\n",
      "Speed: 0.0ms preprocess, 190.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 171.2ms\n",
      "Speed: 3.0ms preprocess, 171.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.9ms\n",
      "Speed: 1.5ms preprocess, 170.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 171.1ms\n",
      "Speed: 4.0ms preprocess, 171.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.3ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.6ms preprocess, 156.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 151.8ms\n",
      "Speed: 5.0ms preprocess, 151.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 151.7ms\n",
      "Speed: 2.0ms preprocess, 151.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 163.5ms\n",
      "Speed: 3.4ms preprocess, 163.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.5ms\n",
      "Speed: 3.0ms preprocess, 188.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 179.0ms\n",
      "Speed: 3.0ms preprocess, 179.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.3ms\n",
      "Speed: 3.0ms preprocess, 186.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.2ms\n",
      "Speed: 0.0ms preprocess, 190.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 181.8ms\n",
      "Speed: 3.0ms preprocess, 181.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 155.0ms\n",
      "Speed: 2.0ms preprocess, 155.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.7ms\n",
      "Speed: 0.0ms preprocess, 202.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 182.9ms\n",
      "Speed: 3.0ms preprocess, 182.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.9ms\n",
      "Speed: 4.0ms preprocess, 189.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.3ms\n",
      "Speed: 0.0ms preprocess, 191.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 208.2ms\n",
      "Speed: 2.0ms preprocess, 208.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.5ms\n",
      "Speed: 0.0ms preprocess, 198.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.4ms\n",
      "Speed: 4.0ms preprocess, 166.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 164.2ms\n",
      "Speed: 3.0ms preprocess, 164.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 164.5ms\n",
      "Speed: 1.4ms preprocess, 164.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.0ms\n",
      "Speed: 3.0ms preprocess, 156.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.3ms\n",
      "Speed: 3.0ms preprocess, 180.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.9ms\n",
      "Speed: 2.0ms preprocess, 170.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.5ms\n",
      "Speed: 3.2ms preprocess, 183.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.9ms\n",
      "Speed: 3.0ms preprocess, 195.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 181.4ms\n",
      "Speed: 4.0ms preprocess, 181.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.5ms\n",
      "Speed: 4.0ms preprocess, 165.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.4ms\n",
      "Speed: 3.0ms preprocess, 177.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.3ms\n",
      "Speed: 3.3ms preprocess, 169.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 164.0ms\n",
      "Speed: 2.0ms preprocess, 164.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 160.4ms\n",
      "Speed: 3.0ms preprocess, 160.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 160.1ms\n",
      "Speed: 3.0ms preprocess, 160.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 160.6ms\n",
      "Speed: 4.0ms preprocess, 160.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 163.5ms\n",
      "Speed: 3.0ms preprocess, 163.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.4ms\n",
      "Speed: 2.0ms preprocess, 172.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.2ms\n",
      "Speed: 2.5ms preprocess, 161.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.2ms\n",
      "Speed: 2.0ms preprocess, 168.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 153.5ms\n",
      "Speed: 3.0ms preprocess, 153.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.1ms\n",
      "Speed: 3.0ms preprocess, 177.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 176.0ms\n",
      "Speed: 2.9ms preprocess, 176.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.9ms\n",
      "Speed: 0.0ms preprocess, 195.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.4ms\n",
      "Speed: 0.0ms preprocess, 154.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.2ms\n",
      "Speed: 3.7ms preprocess, 168.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.7ms\n",
      "Speed: 0.0ms preprocess, 158.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.1ms\n",
      "Speed: 3.0ms preprocess, 196.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.6ms\n",
      "Speed: 5.2ms preprocess, 185.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.1ms\n",
      "Speed: 4.0ms preprocess, 190.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.2ms\n",
      "Speed: 3.0ms preprocess, 193.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.7ms\n",
      "Speed: 0.0ms preprocess, 183.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.6ms\n",
      "Speed: 2.6ms preprocess, 172.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.3ms\n",
      "Speed: 5.0ms preprocess, 189.3ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 217.5ms\n",
      "Speed: 4.0ms preprocess, 217.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.4ms\n",
      "Speed: 0.0ms preprocess, 186.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.8ms\n",
      "Speed: 3.0ms preprocess, 175.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 218.6ms\n",
      "Speed: 0.5ms preprocess, 218.6ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.7ms\n",
      "Speed: 3.6ms preprocess, 156.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.4ms\n",
      "Speed: 0.0ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.9ms\n",
      "Speed: 0.0ms preprocess, 177.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 141.5ms\n",
      "Speed: 0.0ms preprocess, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 135.7ms\n",
      "Speed: 3.0ms preprocess, 135.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 135.4ms\n",
      "Speed: 4.0ms preprocess, 135.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 159.5ms\n",
      "Speed: 0.0ms preprocess, 159.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.2ms\n",
      "Speed: 0.0ms preprocess, 196.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.6ms\n",
      "Speed: 0.0ms preprocess, 161.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.0ms\n",
      "Speed: 1.8ms preprocess, 185.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.8ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 185.8ms inference, 17.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.4ms\n",
      "Speed: 2.0ms preprocess, 158.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 167.0ms\n",
      "Speed: 3.0ms preprocess, 167.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 178.9ms\n",
      "Speed: 0.0ms preprocess, 178.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.5ms\n",
      "Speed: 4.7ms preprocess, 199.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.8ms\n",
      "Speed: 4.0ms preprocess, 194.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.2ms\n",
      "Speed: 3.5ms preprocess, 158.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.3ms\n",
      "Speed: 4.7ms preprocess, 172.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.7ms\n",
      "Speed: 0.0ms preprocess, 174.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.0ms\n",
      "Speed: 3.3ms preprocess, 168.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.4ms\n",
      "Speed: 0.0ms preprocess, 203.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.0ms\n",
      "Speed: 0.0ms preprocess, 180.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.1ms\n",
      "Speed: 0.0ms preprocess, 202.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.1ms\n",
      "Speed: 4.0ms preprocess, 154.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.1ms\n",
      "Speed: 3.0ms preprocess, 165.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 204.0ms\n",
      "Speed: 4.0ms preprocess, 204.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.8ms\n",
      "Speed: 3.8ms preprocess, 177.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.3ms\n",
      "Speed: 4.0ms preprocess, 169.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.5ms\n",
      "Speed: 0.0ms preprocess, 194.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 163.9ms\n",
      "Speed: 0.0ms preprocess, 163.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.7ms\n",
      "Speed: 3.7ms preprocess, 187.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.4ms\n",
      "Speed: 0.0ms preprocess, 199.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 167.6ms\n",
      "Speed: 4.0ms preprocess, 167.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 157.2ms\n",
      "Speed: 0.0ms preprocess, 157.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.0ms\n",
      "Speed: 0.0ms preprocess, 189.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.4ms\n",
      "Speed: 0.0ms preprocess, 189.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.0ms\n",
      "Speed: 4.2ms preprocess, 184.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.7ms\n",
      "Speed: 0.0ms preprocess, 188.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.8ms\n",
      "Speed: 0.0ms preprocess, 187.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.0ms\n",
      "Speed: 4.6ms preprocess, 198.0ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.9ms\n",
      "Speed: 0.0ms preprocess, 173.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 211.0ms\n",
      "Speed: 0.0ms preprocess, 211.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.6ms\n",
      "Speed: 0.0ms preprocess, 173.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 206.2ms\n",
      "Speed: 0.0ms preprocess, 206.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 181.5ms\n",
      "Speed: 1.2ms preprocess, 181.5ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 204.4ms\n",
      "Speed: 0.0ms preprocess, 204.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.1ms\n",
      "Speed: 0.0ms preprocess, 189.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.7ms\n",
      "Speed: 0.0ms preprocess, 188.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.4ms\n",
      "Speed: 0.0ms preprocess, 190.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.4ms\n",
      "Speed: 0.0ms preprocess, 189.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.4ms\n",
      "Speed: 4.5ms preprocess, 168.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.7ms\n",
      "Speed: 0.0ms preprocess, 196.7ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.6ms\n",
      "Speed: 4.7ms preprocess, 174.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 157.4ms\n",
      "Speed: 0.0ms preprocess, 157.4ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.6ms\n",
      "Speed: 0.0ms preprocess, 172.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.6ms\n",
      "Speed: 0.0ms preprocess, 172.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 182.8ms\n",
      "Speed: 0.0ms preprocess, 182.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.1ms\n",
      "Speed: 1.6ms preprocess, 161.1ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.2ms\n",
      "Speed: 0.0ms preprocess, 203.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.7ms\n",
      "Speed: 0.0ms preprocess, 188.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.1ms\n",
      "Speed: 0.0ms preprocess, 173.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 204.7ms\n",
      "Speed: 0.0ms preprocess, 204.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.1ms\n",
      "Speed: 0.0ms preprocess, 202.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.4ms\n",
      "Speed: 0.0ms preprocess, 188.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.1ms\n",
      "Speed: 0.0ms preprocess, 188.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.4ms\n",
      "Speed: 0.0ms preprocess, 188.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.2ms\n",
      "Speed: 0.0ms preprocess, 189.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.1ms\n",
      "Speed: 0.0ms preprocess, 173.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.5ms\n",
      "Speed: 0.0ms preprocess, 154.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 142.1ms\n",
      "Speed: 0.0ms preprocess, 142.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.3ms\n",
      "Speed: 0.0ms preprocess, 194.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 204.9ms\n",
      "Speed: 1.7ms preprocess, 204.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.9ms\n",
      "Speed: 0.0ms preprocess, 186.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.1ms\n",
      "Speed: 0.0ms preprocess, 180.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.4ms\n",
      "Speed: 0.0ms preprocess, 188.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 174.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.2ms\n",
      "Speed: 1.6ms preprocess, 172.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.8ms\n",
      "Speed: 0.0ms preprocess, 187.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.4ms\n",
      "Speed: 0.0ms preprocess, 174.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 225.6ms\n",
      "Speed: 0.0ms preprocess, 225.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.3ms\n",
      "Speed: 1.0ms preprocess, 197.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.6ms\n",
      "Speed: 4.0ms preprocess, 154.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.6ms\n",
      "Speed: 0.0ms preprocess, 170.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 258.9ms\n",
      "Speed: 4.7ms preprocess, 258.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 153.8ms\n",
      "Speed: 2.9ms preprocess, 153.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 155.2ms\n",
      "Speed: 2.0ms preprocess, 155.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.4ms\n",
      "Speed: 0.0ms preprocess, 165.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 179.2ms\n",
      "Speed: 2.5ms preprocess, 179.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.1ms\n",
      "Speed: 4.2ms preprocess, 170.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.6ms\n",
      "Speed: 4.0ms preprocess, 185.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.6ms\n",
      "Speed: 0.0ms preprocess, 194.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.8ms\n",
      "Speed: 0.0ms preprocess, 190.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.5ms\n",
      "Speed: 0.0ms preprocess, 198.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.9ms\n",
      "Speed: 0.0ms preprocess, 197.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.1ms\n",
      "Speed: 0.0ms preprocess, 194.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.7ms\n",
      "Speed: 0.0ms preprocess, 199.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.1ms\n",
      "Speed: 0.0ms preprocess, 200.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.8ms\n",
      "Speed: 0.0ms preprocess, 197.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.2ms\n",
      "Speed: 2.1ms preprocess, 148.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.0ms\n",
      "Speed: 2.0ms preprocess, 166.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.6ms\n",
      "Speed: 0.0ms preprocess, 169.6ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.9ms\n",
      "Speed: 1.0ms preprocess, 148.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.7ms\n",
      "Speed: 1.8ms preprocess, 161.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.0ms\n",
      "Speed: 4.4ms preprocess, 169.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 159.1ms\n",
      "Speed: 1.3ms preprocess, 159.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 164.3ms\n",
      "Speed: 1.0ms preprocess, 164.3ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 157.4ms\n",
      "Speed: 0.0ms preprocess, 157.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 163.6ms\n",
      "Speed: 3.0ms preprocess, 163.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.9ms\n",
      "Speed: 0.0ms preprocess, 161.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.7ms\n",
      "Speed: 1.0ms preprocess, 165.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.5ms\n",
      "Speed: 2.4ms preprocess, 183.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 162.1ms\n",
      "Speed: 3.0ms preprocess, 162.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 143.6ms\n",
      "Speed: 2.0ms preprocess, 143.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 150.8ms\n",
      "Speed: 2.0ms preprocess, 150.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.9ms\n",
      "Speed: 3.0ms preprocess, 148.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.9ms\n",
      "Speed: 0.0ms preprocess, 156.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 192.4ms\n",
      "Speed: 4.0ms preprocess, 192.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.6ms\n",
      "Speed: 4.0ms preprocess, 194.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.1ms\n",
      "Speed: 3.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.4ms\n",
      "Speed: 0.0ms preprocess, 203.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.7ms\n",
      "Speed: 0.0ms preprocess, 202.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.5ms\n",
      "Speed: 0.0ms preprocess, 205.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.0ms\n",
      "Speed: 3.5ms preprocess, 203.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.2ms\n",
      "Speed: 0.0ms preprocess, 200.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.0ms\n",
      "Speed: 3.0ms preprocess, 196.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.7ms\n",
      "Speed: 0.0ms preprocess, 187.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.3ms\n",
      "Speed: 0.0ms preprocess, 186.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.4ms\n",
      "Speed: 3.0ms preprocess, 172.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.1ms\n",
      "Speed: 3.0ms preprocess, 185.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.8ms\n",
      "Speed: 0.0ms preprocess, 202.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.9ms\n",
      "Speed: 6.4ms preprocess, 198.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.4ms\n",
      "Speed: 3.1ms preprocess, 194.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.1ms\n",
      "Speed: 2.1ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 210.0ms\n",
      "Speed: 0.0ms preprocess, 210.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.3ms\n",
      "Speed: 0.0ms preprocess, 205.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.0ms\n",
      "Speed: 4.0ms preprocess, 205.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.7ms\n",
      "Speed: 0.5ms preprocess, 191.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.3ms\n",
      "Speed: 3.7ms preprocess, 195.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.3ms\n",
      "Speed: 3.0ms preprocess, 193.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.0ms\n",
      "Speed: 0.0ms preprocess, 190.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.2ms\n",
      "Speed: 0.0ms preprocess, 184.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Face, 187.4ms\n",
      "Speed: 3.2ms preprocess, 187.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 181.2ms\n",
      "Speed: 3.1ms preprocess, 181.2ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.0ms\n",
      "Speed: 0.0ms preprocess, 184.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 201.9ms\n",
      "Speed: 0.0ms preprocess, 201.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.9ms\n",
      "Speed: 0.0ms preprocess, 189.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.7ms\n",
      "Speed: 0.0ms preprocess, 188.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.0ms\n",
      "Speed: 0.0ms preprocess, 203.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 216.7ms\n",
      "Speed: 4.5ms preprocess, 216.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.3ms\n",
      "Speed: 3.0ms preprocess, 199.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.9ms\n",
      "Speed: 2.4ms preprocess, 177.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 192.3ms\n",
      "Speed: 4.5ms preprocess, 192.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 206.3ms\n",
      "Speed: 0.0ms preprocess, 206.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.5ms\n",
      "Speed: 0.0ms preprocess, 202.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.2ms\n",
      "Speed: 4.0ms preprocess, 186.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.1ms\n",
      "Speed: 0.0ms preprocess, 190.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.2ms\n",
      "Speed: 3.0ms preprocess, 193.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 206.2ms\n",
      "Speed: 0.0ms preprocess, 206.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.2ms\n",
      "Speed: 0.0ms preprocess, 198.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.8ms\n",
      "Speed: 0.0ms preprocess, 197.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 210.9ms\n",
      "Speed: 3.0ms preprocess, 210.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.4ms\n",
      "Speed: 0.0ms preprocess, 191.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.4ms\n",
      "Speed: 4.0ms preprocess, 196.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.8ms\n",
      "Speed: 5.6ms preprocess, 199.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.6ms\n",
      "Speed: 0.0ms preprocess, 195.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.7ms\n",
      "Speed: 0.0ms preprocess, 202.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.2ms\n",
      "Speed: 0.0ms preprocess, 186.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.9ms\n",
      "Speed: 0.0ms preprocess, 196.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.0ms\n",
      "Speed: 1.8ms preprocess, 198.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.8ms\n",
      "Speed: 0.5ms preprocess, 172.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 201.3ms\n",
      "Speed: 0.0ms preprocess, 201.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.2ms\n",
      "Speed: 0.0ms preprocess, 196.2ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.1ms\n",
      "Speed: 0.0ms preprocess, 199.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.4ms\n",
      "Speed: 0.0ms preprocess, 195.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.5ms\n",
      "Speed: 3.8ms preprocess, 180.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.8ms\n",
      "Speed: 0.0ms preprocess, 203.8ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.2ms\n",
      "Speed: 4.0ms preprocess, 197.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.4ms\n",
      "Speed: 6.2ms preprocess, 196.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.0ms\n",
      "Speed: 0.0ms preprocess, 205.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.4ms\n",
      "Speed: 3.0ms preprocess, 189.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.5ms\n",
      "Speed: 0.0ms preprocess, 196.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.8ms\n",
      "Speed: 0.0ms preprocess, 191.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 222.1ms\n",
      "Speed: 0.0ms preprocess, 222.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.5ms\n",
      "Speed: 9.6ms preprocess, 189.5ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.6ms\n",
      "Speed: 0.0ms preprocess, 166.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.7ms\n",
      "Speed: 0.0ms preprocess, 187.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.5ms\n",
      "Speed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 160.0ms\n",
      "Speed: 0.0ms preprocess, 160.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 171.0ms\n",
      "Speed: 0.0ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.1ms\n",
      "Speed: 0.0ms preprocess, 189.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.4ms\n",
      "Speed: 3.3ms preprocess, 169.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 163.4ms\n",
      "Speed: 0.0ms preprocess, 163.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 167.0ms\n",
      "Speed: 0.0ms preprocess, 167.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.4ms\n",
      "Speed: 5.7ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 179.4ms\n",
      "Speed: 3.0ms preprocess, 179.4ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 182.4ms\n",
      "Speed: 0.0ms preprocess, 182.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.1ms\n",
      "Speed: 0.0ms preprocess, 154.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.6ms\n",
      "Speed: 0.0ms preprocess, 169.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.3ms\n",
      "Speed: 2.0ms preprocess, 180.3ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.3ms\n",
      "Speed: 0.0ms preprocess, 185.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.4ms\n",
      "Speed: 0.0ms preprocess, 187.4ms inference, 15.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.0ms\n",
      "Speed: 0.0ms preprocess, 166.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 176.9ms\n",
      "Speed: 3.9ms preprocess, 176.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.4ms\n",
      "Speed: 4.0ms preprocess, 185.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 196.3ms\n",
      "Speed: 0.0ms preprocess, 196.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 179.6ms\n",
      "Speed: 0.0ms preprocess, 179.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Face, 171.1ms\n",
      "Speed: 0.0ms preprocess, 171.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.6ms\n",
      "Speed: 3.8ms preprocess, 183.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.0ms\n",
      "Speed: 0.0ms preprocess, 186.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 241.1ms\n",
      "Speed: 3.2ms preprocess, 241.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.0ms\n",
      "Speed: 0.0ms preprocess, 169.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.3ms\n",
      "Speed: 2.8ms preprocess, 165.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 176.5ms\n",
      "Speed: 0.0ms preprocess, 176.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.1ms\n",
      "Speed: 3.2ms preprocess, 173.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.8ms\n",
      "Speed: 2.5ms preprocess, 197.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.5ms\n",
      "Speed: 3.0ms preprocess, 173.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.4ms\n",
      "Speed: 4.0ms preprocess, 172.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.0ms\n",
      "Speed: 5.0ms preprocess, 184.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.3ms\n",
      "Speed: 2.4ms preprocess, 184.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.3ms\n",
      "Speed: 3.8ms preprocess, 202.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.3ms\n",
      "Speed: 0.0ms preprocess, 169.3ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.1ms\n",
      "Speed: 1.2ms preprocess, 166.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.7ms\n",
      "Speed: 3.0ms preprocess, 168.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.1ms\n",
      "Speed: 0.0ms preprocess, 175.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 160.1ms\n",
      "Speed: 3.8ms preprocess, 160.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.0ms\n",
      "Speed: 3.0ms preprocess, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 159.3ms\n",
      "Speed: 0.0ms preprocess, 159.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 153.5ms\n",
      "Speed: 4.9ms preprocess, 153.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 160.4ms\n",
      "Speed: 0.0ms preprocess, 160.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 157.1ms\n",
      "Speed: 0.0ms preprocess, 157.1ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.6ms\n",
      "Speed: 3.3ms preprocess, 186.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.2ms\n",
      "Speed: 3.0ms preprocess, 202.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.2ms\n",
      "Speed: 0.0ms preprocess, 165.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.3ms\n",
      "Speed: 0.0ms preprocess, 158.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.4ms\n",
      "Speed: 0.0ms preprocess, 188.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.3ms\n",
      "Speed: 0.0ms preprocess, 173.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.5ms\n",
      "Speed: 3.6ms preprocess, 138.5ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 159.7ms\n",
      "Speed: 0.0ms preprocess, 159.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 157.4ms\n",
      "Speed: 0.0ms preprocess, 157.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.7ms\n",
      "Speed: 5.1ms preprocess, 205.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 254.8ms\n",
      "Speed: 5.1ms preprocess, 254.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 222.3ms\n",
      "Speed: 1.9ms preprocess, 222.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 284.7ms\n",
      "Speed: 0.0ms preprocess, 284.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 291.8ms\n",
      "Speed: 9.9ms preprocess, 291.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 273.1ms\n",
      "Speed: 0.0ms preprocess, 273.1ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.8ms\n",
      "Speed: 2.0ms preprocess, 187.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.2ms\n",
      "Speed: 3.3ms preprocess, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.4ms\n",
      "Speed: 2.3ms preprocess, 169.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.1ms\n",
      "Speed: 0.0ms preprocess, 161.1ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.0ms\n",
      "Speed: 0.0ms preprocess, 188.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.7ms\n",
      "Speed: 0.0ms preprocess, 188.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.9ms\n",
      "Speed: 0.0ms preprocess, 187.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.3ms\n",
      "Speed: 0.5ms preprocess, 187.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.4ms\n",
      "Speed: 0.0ms preprocess, 193.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.6ms\n",
      "Speed: 5.3ms preprocess, 166.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.8ms\n",
      "Speed: 4.5ms preprocess, 185.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 219.8ms\n",
      "Speed: 0.0ms preprocess, 219.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 221.8ms\n",
      "Speed: 0.0ms preprocess, 221.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 201.3ms\n",
      "Speed: 2.8ms preprocess, 201.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.6ms\n",
      "Speed: 0.0ms preprocess, 197.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.7ms\n",
      "Speed: 4.5ms preprocess, 183.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 178.0ms\n",
      "Speed: 0.0ms preprocess, 178.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.9ms\n",
      "Speed: 0.0ms preprocess, 203.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 215.5ms\n",
      "Speed: 5.5ms preprocess, 215.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.9ms\n",
      "Speed: 2.9ms preprocess, 154.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 159.1ms\n",
      "Speed: 0.0ms preprocess, 159.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.9ms\n",
      "Speed: 5.0ms preprocess, 186.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.1ms\n",
      "Speed: 0.0ms preprocess, 173.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.8ms\n",
      "Speed: 0.0ms preprocess, 188.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.6ms\n",
      "Speed: 0.0ms preprocess, 189.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 153.9ms\n",
      "Speed: 0.0ms preprocess, 153.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Face, 154.3ms\n",
      "Speed: 4.0ms preprocess, 154.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.8ms\n",
      "Speed: 0.0ms preprocess, 172.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.6ms\n",
      "Speed: 0.0ms preprocess, 189.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.3ms\n",
      "Speed: 0.0ms preprocess, 172.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.7ms\n",
      "Speed: 0.0ms preprocess, 194.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.2ms\n",
      "Speed: 0.0ms preprocess, 175.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.6ms\n",
      "Speed: 0.0ms preprocess, 180.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.7ms\n",
      "Speed: 0.0ms preprocess, 188.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.3ms\n",
      "Speed: 0.0ms preprocess, 188.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.1ms\n",
      "Speed: 0.0ms preprocess, 188.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.9ms\n",
      "Speed: 3.9ms preprocess, 175.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.3ms\n",
      "Speed: 3.5ms preprocess, 183.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.3ms\n",
      "Speed: 0.0ms preprocess, 189.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.0ms\n",
      "Speed: 0.0ms preprocess, 189.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.3ms\n",
      "Speed: 0.0ms preprocess, 177.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.6ms\n",
      "Speed: 0.0ms preprocess, 175.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.4ms\n",
      "Speed: 6.9ms preprocess, 172.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.0ms\n",
      "Speed: 0.0ms preprocess, 189.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.3ms\n",
      "Speed: 0.0ms preprocess, 197.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.5ms\n",
      "Speed: 0.0ms preprocess, 188.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 141.2ms\n",
      "Speed: 4.9ms preprocess, 141.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.6ms\n",
      "Speed: 0.0ms preprocess, 173.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.3ms\n",
      "Speed: 0.0ms preprocess, 188.3ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.2ms\n",
      "Speed: 0.0ms preprocess, 190.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.8ms\n",
      "Speed: 0.0ms preprocess, 173.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.2ms\n",
      "Speed: 6.0ms preprocess, 184.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.4ms\n",
      "Speed: 0.0ms preprocess, 189.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 204.5ms\n",
      "Speed: 0.0ms preprocess, 204.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 189.8ms\n",
      "Speed: 0.0ms preprocess, 189.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.2ms\n",
      "Speed: 0.0ms preprocess, 189.2ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.5ms\n",
      "Speed: 5.7ms preprocess, 199.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.5ms\n",
      "Speed: 0.0ms preprocess, 202.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 199.8ms\n",
      "Speed: 4.5ms preprocess, 199.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 194.4ms\n",
      "Speed: 0.0ms preprocess, 194.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 174.3ms\n",
      "Speed: 0.0ms preprocess, 174.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 164.8ms\n",
      "Speed: 0.0ms preprocess, 164.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.5ms\n",
      "Speed: 0.0ms preprocess, 173.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 162.3ms\n",
      "Speed: 0.0ms preprocess, 162.3ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.9ms\n",
      "Speed: 0.0ms preprocess, 193.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 274.9ms\n",
      "Speed: 0.0ms preprocess, 274.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.4ms\n",
      "Speed: 0.0ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 209.1ms\n",
      "Speed: 0.0ms preprocess, 209.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 269.3ms\n",
      "Speed: 0.0ms preprocess, 269.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.2ms\n",
      "Speed: 0.0ms preprocess, 189.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.8ms\n",
      "Speed: 0.0ms preprocess, 203.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.4ms\n",
      "Speed: 1.8ms preprocess, 193.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 207.5ms\n",
      "Speed: 0.0ms preprocess, 207.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 220.4ms\n",
      "Speed: 0.0ms preprocess, 220.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 220.6ms\n",
      "Speed: 0.0ms preprocess, 220.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 210.7ms\n",
      "Speed: 0.0ms preprocess, 210.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.5ms\n",
      "Speed: 6.0ms preprocess, 200.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.1ms\n",
      "Speed: 0.0ms preprocess, 205.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.3ms\n",
      "Speed: 0.0ms preprocess, 189.3ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 173.1ms\n",
      "Speed: 0.0ms preprocess, 173.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.1ms\n",
      "Speed: 0.0ms preprocess, 187.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.9ms\n",
      "Speed: 0.0ms preprocess, 188.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 203.7ms\n",
      "Speed: 0.0ms preprocess, 203.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.1ms\n",
      "Speed: 3.2ms preprocess, 184.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.5ms\n",
      "Speed: 5.6ms preprocess, 200.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.5ms\n",
      "Speed: 2.5ms preprocess, 202.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 204.7ms\n",
      "Speed: 0.0ms preprocess, 204.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 225.3ms\n",
      "Speed: 0.0ms preprocess, 225.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 210.4ms\n",
      "Speed: 0.0ms preprocess, 210.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.9ms\n",
      "Speed: 4.0ms preprocess, 193.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.3ms\n",
      "Speed: 0.0ms preprocess, 195.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Face, 201.6ms\n",
      "Speed: 3.8ms preprocess, 201.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 208.3ms\n",
      "Speed: 4.4ms preprocess, 208.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.0ms\n",
      "Speed: 0.0ms preprocess, 198.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.3ms\n",
      "Speed: 3.3ms preprocess, 194.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.4ms\n",
      "Speed: 4.3ms preprocess, 188.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.8ms\n",
      "Speed: 2.3ms preprocess, 174.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.2ms\n",
      "Speed: 4.0ms preprocess, 189.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 177.4ms\n",
      "Speed: 3.8ms preprocess, 177.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.5ms\n",
      "Speed: 0.0ms preprocess, 180.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.2ms\n",
      "Speed: 0.0ms preprocess, 186.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.2ms\n",
      "Speed: 0.0ms preprocess, 200.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.7ms\n",
      "Speed: 2.5ms preprocess, 183.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.4ms\n",
      "Speed: 0.0ms preprocess, 190.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.4ms\n",
      "Speed: 3.0ms preprocess, 186.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.2ms\n",
      "Speed: 0.0ms preprocess, 205.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.0ms\n",
      "Speed: 6.2ms preprocess, 193.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.7ms\n",
      "Speed: 5.0ms preprocess, 183.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 197.5ms\n",
      "Speed: 3.0ms preprocess, 197.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 176.6ms\n",
      "Speed: 3.0ms preprocess, 176.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 192.5ms\n",
      "Speed: 2.2ms preprocess, 192.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 181.6ms\n",
      "Speed: 2.5ms preprocess, 181.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 192.3ms\n",
      "Speed: 0.0ms preprocess, 192.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 207.0ms\n",
      "Speed: 0.0ms preprocess, 207.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 198.9ms\n",
      "Speed: 0.0ms preprocess, 198.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.0ms\n",
      "Speed: 4.0ms preprocess, 189.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 193.6ms\n",
      "Speed: 4.0ms preprocess, 193.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 205.0ms\n",
      "Speed: 0.0ms preprocess, 205.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 197.9ms\n",
      "Speed: 3.4ms preprocess, 197.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.4ms\n",
      "Speed: 0.0ms preprocess, 190.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 202.0ms\n",
      "Speed: 3.2ms preprocess, 202.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 185.0ms\n",
      "Speed: 0.0ms preprocess, 185.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 202.7ms\n",
      "Speed: 0.0ms preprocess, 202.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.3ms\n",
      "Speed: 0.0ms preprocess, 190.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 192.6ms\n",
      "Speed: 3.6ms preprocess, 192.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 203.5ms\n",
      "Speed: 2.2ms preprocess, 203.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 196.8ms\n",
      "Speed: 0.0ms preprocess, 196.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 206.0ms\n",
      "Speed: 0.0ms preprocess, 206.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 189.1ms\n",
      "Speed: 4.0ms preprocess, 189.1ms inference, 9.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 199.5ms\n",
      "Speed: 4.5ms preprocess, 199.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 195.9ms\n",
      "Speed: 2.0ms preprocess, 195.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 202.1ms\n",
      "Speed: 4.3ms preprocess, 202.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 171.8ms\n",
      "Speed: 4.0ms preprocess, 171.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 205.2ms\n",
      "Speed: 0.0ms preprocess, 205.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 163.8ms\n",
      "Speed: 3.0ms preprocess, 163.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 171.9ms\n",
      "Speed: 0.0ms preprocess, 171.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.5ms\n",
      "Speed: 2.0ms preprocess, 156.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.3ms\n",
      "Speed: 3.0ms preprocess, 168.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.9ms\n",
      "Speed: 2.0ms preprocess, 175.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 167.9ms\n",
      "Speed: 4.0ms preprocess, 167.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.3ms\n",
      "Speed: 3.0ms preprocess, 190.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 197.7ms\n",
      "Speed: 2.0ms preprocess, 197.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 170.4ms\n",
      "Speed: 4.3ms preprocess, 170.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 168.9ms\n",
      "Speed: 1.8ms preprocess, 168.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 181.9ms\n",
      "Speed: 2.0ms preprocess, 181.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.8ms\n",
      "Speed: 2.0ms preprocess, 183.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.3ms\n",
      "Speed: 0.0ms preprocess, 180.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 183.9ms\n",
      "Speed: 4.0ms preprocess, 183.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 196.4ms\n",
      "Speed: 3.0ms preprocess, 196.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 188.4ms\n",
      "Speed: 3.0ms preprocess, 188.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 182.0ms\n",
      "Speed: 2.5ms preprocess, 182.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 182.9ms\n",
      "Speed: 3.0ms preprocess, 182.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 176.2ms\n",
      "Speed: 3.0ms preprocess, 176.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 182.4ms\n",
      "Speed: 4.2ms preprocess, 182.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.8ms\n",
      "Speed: 0.0ms preprocess, 183.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 178.5ms\n",
      "Speed: 0.0ms preprocess, 178.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Face, 171.1ms\n",
      "Speed: 0.0ms preprocess, 171.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.7ms\n",
      "Speed: 0.0ms preprocess, 175.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.4ms\n",
      "Speed: 0.0ms preprocess, 161.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 154.2ms\n",
      "Speed: 2.6ms preprocess, 154.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 146.8ms\n",
      "Speed: 2.4ms preprocess, 146.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 181.8ms\n",
      "Speed: 1.5ms preprocess, 181.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.7ms\n",
      "Speed: 3.0ms preprocess, 191.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 176.1ms\n",
      "Speed: 3.5ms preprocess, 176.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 242.0ms\n",
      "Speed: 4.3ms preprocess, 242.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.6ms\n",
      "Speed: 3.0ms preprocess, 195.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.4ms\n",
      "Speed: 4.0ms preprocess, 191.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.6ms\n",
      "Speed: 4.0ms preprocess, 168.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.1ms\n",
      "Speed: 2.0ms preprocess, 180.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 163.1ms\n",
      "Speed: 4.0ms preprocess, 163.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 164.7ms\n",
      "Speed: 0.0ms preprocess, 164.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.8ms\n",
      "Speed: 2.5ms preprocess, 170.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 179.2ms\n",
      "Speed: 0.0ms preprocess, 179.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.5ms\n",
      "Speed: 3.0ms preprocess, 195.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.9ms\n",
      "Speed: 0.0ms preprocess, 166.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.3ms\n",
      "Speed: 0.0ms preprocess, 184.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 165.6ms\n",
      "Speed: 0.0ms preprocess, 165.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 179.0ms\n",
      "Speed: 1.8ms preprocess, 179.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.5ms\n",
      "Speed: 0.0ms preprocess, 189.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.7ms\n",
      "Speed: 4.0ms preprocess, 180.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.3ms\n",
      "Speed: 0.0ms preprocess, 168.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.6ms\n",
      "Speed: 3.0ms preprocess, 183.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 209.5ms\n",
      "Speed: 0.5ms preprocess, 209.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 210.6ms\n",
      "Speed: 1.0ms preprocess, 210.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.3ms\n",
      "Speed: 3.0ms preprocess, 180.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 173.2ms\n",
      "Speed: 4.0ms preprocess, 173.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 222.7ms\n",
      "Speed: 10.0ms preprocess, 222.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 176.1ms\n",
      "Speed: 3.0ms preprocess, 176.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.9ms\n",
      "Speed: 0.0ms preprocess, 200.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 208.2ms\n",
      "Speed: 3.7ms preprocess, 208.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 151.5ms\n",
      "Speed: 1.9ms preprocess, 151.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 171.7ms\n",
      "Speed: 0.0ms preprocess, 171.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 176.3ms\n",
      "Speed: 0.0ms preprocess, 176.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.3ms\n",
      "Speed: 0.0ms preprocess, 200.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.0ms\n",
      "Speed: 0.0ms preprocess, 175.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.0ms\n",
      "Speed: 3.0ms preprocess, 183.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.6ms\n",
      "Speed: 5.5ms preprocess, 195.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.4ms\n",
      "Speed: 3.0ms preprocess, 193.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.4ms\n",
      "Speed: 3.6ms preprocess, 185.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.0ms\n",
      "Speed: 0.0ms preprocess, 200.0ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 184.3ms\n",
      "Speed: 0.0ms preprocess, 184.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.2ms\n",
      "Speed: 3.0ms preprocess, 187.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 205.0ms\n",
      "Speed: 0.0ms preprocess, 205.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 193.8ms\n",
      "Speed: 3.0ms preprocess, 193.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 201.0ms\n",
      "Speed: 0.0ms preprocess, 201.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.2ms\n",
      "Speed: 3.2ms preprocess, 195.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 208.0ms\n",
      "Speed: 0.0ms preprocess, 208.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 201.9ms\n",
      "Speed: 0.0ms preprocess, 201.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 186.5ms\n",
      "Speed: 0.0ms preprocess, 186.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 182.5ms\n",
      "Speed: 2.1ms preprocess, 182.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 183.5ms\n",
      "Speed: 3.0ms preprocess, 183.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 166.6ms\n",
      "Speed: 2.0ms preprocess, 166.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.6ms\n",
      "Speed: 0.0ms preprocess, 174.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 187.8ms\n",
      "Speed: 2.0ms preprocess, 187.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 155.3ms\n",
      "Speed: 3.4ms preprocess, 155.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 156.8ms\n",
      "Speed: 0.0ms preprocess, 156.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 168.0ms\n",
      "Speed: 2.3ms preprocess, 168.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.7ms\n",
      "Speed: 5.3ms preprocess, 169.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 167.3ms\n",
      "Speed: 0.0ms preprocess, 167.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.5ms\n",
      "Speed: 2.5ms preprocess, 185.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 271.3ms\n",
      "Speed: 2.9ms preprocess, 271.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Face, 203.8ms\n",
      "Speed: 6.6ms preprocess, 203.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 180.4ms\n",
      "Speed: 6.1ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.9ms\n",
      "Speed: 3.5ms preprocess, 170.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.1ms\n",
      "Speed: 0.0ms preprocess, 191.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 200.6ms\n",
      "Speed: 0.0ms preprocess, 200.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 199.5ms\n",
      "Speed: 4.9ms preprocess, 199.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 195.5ms\n",
      "Speed: 1.1ms preprocess, 195.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 234.0ms\n",
      "Speed: 4.6ms preprocess, 234.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 212.6ms\n",
      "Speed: 2.8ms preprocess, 212.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 191.2ms\n",
      "Speed: 0.0ms preprocess, 191.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 170.3ms\n",
      "Speed: 1.6ms preprocess, 170.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Faces, 172.4ms\n",
      "Speed: 0.0ms preprocess, 172.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.0ms\n",
      "Speed: 2.5ms preprocess, 172.0ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 175.1ms\n",
      "Speed: 0.0ms preprocess, 175.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 138.8ms\n",
      "Speed: 1.8ms preprocess, 138.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 141.6ms\n",
      "Speed: 0.0ms preprocess, 141.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 126.5ms\n",
      "Speed: 0.0ms preprocess, 126.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 143.7ms\n",
      "Speed: 0.0ms preprocess, 143.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.8ms\n",
      "Speed: 3.3ms preprocess, 183.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.3ms\n",
      "Speed: 6.3ms preprocess, 185.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 148.9ms\n",
      "Speed: 1.9ms preprocess, 148.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.6ms\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 149.5ms\n",
      "Speed: 2.0ms preprocess, 149.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 151.0ms\n",
      "Speed: 1.5ms preprocess, 151.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 150.5ms\n",
      "Speed: 2.5ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 144.4ms\n",
      "Speed: 2.1ms preprocess, 144.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 141.8ms\n",
      "Speed: 3.4ms preprocess, 141.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 135.3ms\n",
      "Speed: 3.8ms preprocess, 135.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.0ms\n",
      "Speed: 3.3ms preprocess, 174.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.5ms\n",
      "Speed: 0.0ms preprocess, 172.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 169.8ms\n",
      "Speed: 4.0ms preprocess, 169.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 161.8ms\n",
      "Speed: 2.0ms preprocess, 161.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 158.4ms\n",
      "Speed: 1.5ms preprocess, 158.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 159.8ms\n",
      "Speed: 3.1ms preprocess, 159.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.2ms\n",
      "Speed: 3.0ms preprocess, 172.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 178.6ms\n",
      "Speed: 5.0ms preprocess, 178.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 170.5ms\n",
      "Speed: 3.0ms preprocess, 170.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 153.7ms\n",
      "Speed: 3.0ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 172.2ms\n",
      "Speed: 2.5ms preprocess, 172.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 182.5ms\n",
      "Speed: 4.0ms preprocess, 182.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 185.1ms\n",
      "Speed: 3.3ms preprocess, 185.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 194.8ms\n",
      "Speed: 0.0ms preprocess, 194.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 189.0ms\n",
      "Speed: 3.9ms preprocess, 189.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.3ms\n",
      "Speed: 3.1ms preprocess, 174.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 183.0ms\n",
      "Speed: 3.0ms preprocess, 183.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 174.8ms\n",
      "Speed: 4.0ms preprocess, 174.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Face, 190.1ms\n",
      "Speed: 4.0ms preprocess, 190.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')  # load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt')  # load a custom trained\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detector:\n",
    "    frame_counter = 0\n",
    "    fonts = cv.FONT_HERSHEY_PLAIN\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        frame_counter += 1\n",
    "        ret, frame = cap.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "\n",
    "        # YOLOv8 face detection\n",
    "        results_yolo = model(frame)\n",
    "        faces_yolo = results_yolo[0]  # Assuming the first class is face\n",
    "\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        # MediaPipe face landmark detection\n",
    "        results_mp = face_detector.process(rgb_frame)\n",
    "        frame_height, frame_width, c = frame.shape\n",
    "        if results_mp.detections:\n",
    "            for face in results_mp.detections:\n",
    "                face_react = np.multiply(\n",
    "                    [\n",
    "                        face.location_data.relative_bounding_box.xmin,\n",
    "                        face.location_data.relative_bounding_box.ymin,\n",
    "                        face.location_data.relative_bounding_box.width,\n",
    "                        face.location_data.relative_bounding_box.height,\n",
    "                    ],\n",
    "                    [frame_width, frame_height, frame_width, frame_height]).astype(int)\n",
    "\n",
    "                cv.rectangle(frame, face_react, color=(255, 255, 255), thickness=2)\n",
    "                key_points = np.array([(p.x, p.y) for p in face.location_data.relative_keypoints])\n",
    "                key_points_coords = np.multiply(key_points, [frame_width, frame_height]).astype(int)\n",
    "                for p in key_points_coords:\n",
    "                    cv.circle(frame, p, 4, (255, 255, 255), 2)\n",
    "                    cv.circle(frame, p, 2, (0, 0, 0), -1)\n",
    "\n",
    "        fps = frame_counter / (time.time() - start_time)\n",
    "        cv.putText(frame, f\"FPS: {fps:.2f}\", (30, 30), cv.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 2,)\n",
    "        cv.imshow(\"frame\", frame)\n",
    "        key = cv.waitKey(1)\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83866bc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe' has no attribute 'face_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBAPS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# load a custom trained\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Load MediaPipe Face Landmark Detection\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m mp_face_detection \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_detection\u001b[49m\n\u001b[0;32m     15\u001b[0m mp_face_mesh \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mface_mesh\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create MediaPipe Face Detection and Mesh Detection objects\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mediapipe' has no attribute 'face_detection'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mediapipe import solutions as mp\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')  # load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\detect\\train\\weights\\best.pt')  # load a custom trained\n",
    "\n",
    "# Load MediaPipe Face Landmark Detection\n",
    "mp_face_detection = mp.face_detection\n",
    "mp_face_mesh = mp.face_mesh\n",
    "\n",
    "# Create MediaPipe Face Detection and Mesh Detection objects\n",
    "face_detection = mp_face_detection.FaceDetection()\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform YOLOv8 object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Post-process detections and draw bounding boxes\n",
    "    pred = non_max_suppression(results.pred[0], conf_thres=0.5, iou_thres=0.45)\n",
    "    if pred[0] is not None:\n",
    "        for det in pred[0]:\n",
    "            x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "\n",
    "            # Apply MediaPipe Face Landmark Detection to the face region\n",
    "            face_region = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "            if face_region.shape[0] > 0 and face_region.shape[1] > 0:\n",
    "                # Convert face_region to a PyTorch tensor\n",
    "                face_region_tensor = torch.from_numpy(face_region).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "\n",
    "                # Apply MediaPipe Face Mesh on the PyTorch tensor\n",
    "                face_landmarks = face_mesh.process(face_region_tensor)\n",
    "                if face_landmarks.multi_face_landmarks:\n",
    "                    pass\n",
    "                    # Process face landmarks here\n",
    "\n",
    "    cv2.imshow(\"YOLOv8 Object Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize MediaPipe Face Landmark Detection\n",
    "mp_face_landmarks = mp.solutions.face_landmarks\n",
    "\n",
    "# Initialize Video Capture (or use image)\n",
    "cap = cv2.VideoCapture(0)  # Use webcam (change to image file if needed)\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection, \\\n",
    "     mp_face_landmarks.FaceLandmarks(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_landmarks:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert BGR image to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform Face Detection\n",
    "        detection_results = face_detection.process(rgb_frame)\n",
    "\n",
    "        if detection_results.detections:\n",
    "            for detection in detection_results.detections:\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, _ = frame.shape\n",
    "                x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "\n",
    "                # Perform Face Landmark Detection on detected face region\n",
    "                face_roi = frame[y:y+h, x:x+w]\n",
    "                landmarks_results = face_landmarks.process(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                if landmarks_results.multi_face_landmarks:\n",
    "                    for landmarks in landmarks_results.multi_face_landmarks:\n",
    "                        for landmark in landmarks.landmark:\n",
    "                            x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "                            # Draw the facial landmarks on the frame\n",
    "                            cv2.circle(face_roi, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "                # Draw the bounding box on the frame\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Face Detection with Landmarks', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
